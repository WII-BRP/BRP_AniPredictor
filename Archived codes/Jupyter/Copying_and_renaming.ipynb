{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d80501bf-0951-45c8-b86f-bdfc62d42cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import exifread\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import math\n",
    "import pyfastcopy\n",
    "\n",
    "def list_files_in_directory(directory):\n",
    "    file_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg','.JPG')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_paths.append(file_path)\n",
    "            else:\n",
    "                continue\n",
    "    return file_paths\n",
    "\n",
    "def convert_datetime(dt):\n",
    "    try:\n",
    "        dt = pd.to_datetime(dt, format='%Y-%m-%d %H-%M-%S')\n",
    "        return dt.strftime('%Y%m%d_%H%M%S')\n",
    "    except pd.errors.OutOfBoundsDatetime:\n",
    "        return 'OutOfBoundsDatetime'\n",
    "\n",
    "def clean_path(path):\n",
    "    return os.path.normpath(path)\n",
    "\n",
    "def process_image(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        tags = exifread.process_file(image_file, details=False)\n",
    "        \n",
    "        directory = os.path.dirname(image_path)\n",
    "        filename = os.path.basename(image_path)\n",
    "        filetype_extension = os.path.splitext(filename)[1]\n",
    "        make = tags.get('Image Make', 'N/A')\n",
    "        model = tags.get('Image Model', 'N/A')\n",
    "        datetime_original = tags.get('EXIF DateTimeOriginal', 'N/A')\n",
    "        \n",
    "        return {\n",
    "            'SourceFile': image_path,\n",
    "            'Directory': directory,\n",
    "            'FileName': filename,\n",
    "            'FileTypeExtension': filetype_extension,\n",
    "            'Make': make,\n",
    "            'Model': model,\n",
    "            'DateTimeOriginal': datetime_original\n",
    "        }\n",
    "\n",
    "def read_exif(image_dir):\n",
    "    file_paths = list_files_in_directory(image_dir)\n",
    "    print(len(file_paths))\n",
    "    with ThreadPoolExecutor(20) as executor:  # Adjust max_workers as needed\n",
    "        image_metadata_list = list(executor.map(process_image, file_paths))\n",
    "    exif_info = pd.DataFrame(image_metadata_list)\n",
    "    return exif_info\n",
    "\n",
    "def create_new_filenames(exif_info):\n",
    "    exif_info = exif_info[exif_info[\"DateTimeOriginal\"] != \"N/A\"]\n",
    "    exif_info['Station'] = Station\n",
    "    exif_info['Camera'] = Camera\n",
    "    exif_info['DateTimeOriginal'] = pd.to_datetime(exif_info['DateTimeOriginal'], format='%Y:%m:%d %H:%M:%S')\n",
    "    exif_info['FormattedDateTime'] = exif_info['DateTimeOriginal'].apply(convert_datetime)\n",
    "    exif_info = exif_info.sort_values(by=['Station', 'Camera', 'DateTimeOriginal']).reset_index(drop=True)\n",
    "    exif_info['diff'] = exif_info.groupby(['Station', 'Camera'])['DateTimeOriginal'].diff()\n",
    "    exif_info['image_number']=exif_info.groupby(['Station','Camera']).cumcount()+1\n",
    "    exif_info['Directory'] = exif_info['Directory'].apply(clean_path)\n",
    "    exif_info['SourceFile'] = exif_info['SourceFile'].apply(clean_path)\n",
    "    exif_info['Dest_subfolder_number'] = exif_info['image_number'].apply(lambda x: math.ceil(x / 10000)).astype(str)\n",
    "    exif_info['Dest_Directory'] = (dest_dir + \"\\\\\" + exif_info['Dest_subfolder_number']).apply(clean_path)\n",
    "\n",
    "    ### Add sequence number\n",
    "    threshold = timedelta(seconds=1)\n",
    "    Sequence = []\n",
    "    for i in range(len(exif_info)):\n",
    "        diff = exif_info['diff'][i]\n",
    "        if pd.isna(diff) or diff > threshold:\n",
    "            sequence = 1\n",
    "        else:\n",
    "            sequence = Sequence[i - 1] + 1\n",
    "        Sequence.append(sequence)\n",
    "    exif_info['Sequence'] = Sequence\n",
    "\n",
    "    ### Construct new filename\n",
    "    exif_info['FileNameNew'] = exif_info['Station'] + '_' + exif_info['Camera'] + '_' + exif_info['FormattedDateTime'] + '(' + exif_info['Sequence'].astype(str) + ')' + exif_info['FileTypeExtension']\n",
    "    exif_info['DestFile'] = (exif_info['Dest_Directory'] + \"\\\\\" + exif_info['FileNameNew']).apply(clean_path)\n",
    "    \n",
    "    #copy_dir = []\n",
    "    #for i in range(len(exif_info)):\n",
    "        #d = exif_info['Directory'][i]\n",
    "        #c = os.path.join(dest_drive, \"\\\\\".join(d.split(\"\\\\\")[1:]))\n",
    "        #copy_dir.append(c)\n",
    "\n",
    "    #exif_info['copy_dir'] = copy_dir\n",
    "    #exif_info['SourceFileNew_copy'] = exif_info.apply(lambda row: os.path.join(row['copy_dir'], row['FileNameNew']), axis=1)\n",
    "    return exif_info\n",
    "\n",
    "def rename_images(table):\n",
    "    source_path = table['SourceFile']\n",
    "    target_path = table['DestFile']\n",
    "    os.rename(source_path, target_path)\n",
    "\n",
    "def copy_images(table):\n",
    "    src_files = table['SourceFile']\n",
    "    dest_files = table['DestFile']\n",
    "    with ThreadPoolExecutor(10) as exe:\n",
    "        _ = [exe.submit(shutil.copy, src_path, dest_path) for src_path,dest_path in zip(src_files,dest_files)]\n",
    "\n",
    "def copy_images_batch(table, batch_size=1000):\n",
    "    src_files=table['SourceFile']\n",
    "    dest_files=table['DestFile']\n",
    "    with ThreadPoolExecutor(20) as exe:\n",
    "        for i in range(0, len(src_files), batch_size):\n",
    "            src_batch = src_files[i:i + batch_size]\n",
    "            dest_batch = dest_files[i:i + batch_size]\n",
    "            \n",
    "            batch_tasks = [exe.submit(shutil.copy, src, dest) for src, dest in zip(src_batch, dest_batch)]\n",
    "            # Wait for all tasks in the batch to complete before proceeding to the next batch\n",
    "            _ = [task.result() for task in batch_tasks]\n",
    "            print(f\"First {i+1 * 1000} images copied at {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "554eb294-8fee-4611-b70b-e8773b9472b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\\\\Camera_Trapping\\\\Guzzler_data\\2023\\05092023-06122023(not yet included in above CameraTrap folder)\\Gajaimata\\Gajaimata1\n",
      "Gajaimata\n",
      "Gajaimata1\n"
     ]
    }
   ],
   "source": [
    "camera_dir = r\"I:\\Guzzler_data\\2023\\05092023-06122023(not yet included in above CameraTrap folder)\\Gajaimata\\Gajaimata1\"\n",
    "dest_dir = os.path.join(r\"I:\\\\Camera_Trapping\\\\\",\"\\\\\".join(camera_dir.split(\"\\\\\")[1:]))\n",
    "print(dest_dir)\n",
    "Station = camera_dir.split(\"\\\\\")[-2]\n",
    "print(Station)\n",
    "Camera = camera_dir.split(\"\\\\\")[-1]\n",
    "print(Camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ce24176-ebb6-4f48-b947-67d45d7d5778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20104\\1140405698.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exif_info['Station'] = Station\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20104\\1140405698.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exif_info['Camera'] = Camera\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20104\\1140405698.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exif_info['DateTimeOriginal'] = pd.to_datetime(exif_info['DateTimeOriginal'], format='%Y:%m:%d %H:%M:%S')\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20104\\1140405698.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exif_info['FormattedDateTime'] = exif_info['DateTimeOriginal'].apply(convert_datetime)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:04.905862\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "###Create Renaming Table\n",
    "exif = read_exif(camera_dir)\n",
    "renaming_table=create_new_filenames(exif)\n",
    "end = datetime.datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974cbcee-8542-48bb-a68e-c4ad6dea951c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'renaming_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Copy and rename in batches, based on renaming table\u001b[39;00m\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m----> 4\u001b[0m unique_directories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mrenaming_table\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDest_Directory\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m unique_directories:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(d):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'renaming_table' is not defined"
     ]
    }
   ],
   "source": [
    "### Copy and rename in batches, based on renaming table\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "unique_directories = set(renaming_table['Dest_Directory'])\n",
    "for d in unique_directories:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "copy_images_batch(renaming_table)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed458a17-dc70-4099-a9ec-c0d71a2bf7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f4182-94bc-4152-b919-93848729f3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cfd92c-03c9-4d37-a2f5-5dc844ef3a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79fcdc-0532-4267-9002-d1d1a8792505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076e888-953e-4fbe-b70e-b399e09dcf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2fb2b9-5279-4da0-9489-4d5a7f33cec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204997f-54e2-41cd-a8ef-0e46dc2dc108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5431fa-dcc1-47b3-9e65-45f82909bfee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631d789-bab8-410c-b314-37e1dd01b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Copy and rename based on renaming table\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "unique_directories = set(renaming_table['Dest_Directory'])\n",
    "for d in unique_directories:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "copy_images(renaming_table)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130ba18-13c5-4b40-99d0-6146365cba54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "abb28aec-63c8-42e7-8888-05fe552296f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 1000 images copied at 2023-10-20 10:16:18.606086\n",
      "First 2000 images copied at 2023-10-20 10:16:27.493457\n",
      "First 3000 images copied at 2023-10-20 10:16:41.013794\n",
      "First 4000 images copied at 2023-10-20 10:16:59.139294\n",
      "First 5000 images copied at 2023-10-20 10:17:24.540477\n",
      "First 6000 images copied at 2023-10-20 10:17:53.117812\n",
      "First 7000 images copied at 2023-10-20 10:18:27.001459\n",
      "First 8000 images copied at 2023-10-20 10:19:08.088751\n",
      "First 9000 images copied at 2023-10-20 10:19:49.303451\n",
      "First 10000 images copied at 2023-10-20 10:20:37.117296\n",
      "First 11000 images copied at 2023-10-20 10:20:41.648107\n",
      "First 12000 images copied at 2023-10-20 10:20:50.868103\n",
      "First 13000 images copied at 2023-10-20 10:21:05.305992\n",
      "First 14000 images copied at 2023-10-20 10:21:24.033877\n",
      "First 15000 images copied at 2023-10-20 10:21:45.849361\n",
      "First 16000 images copied at 2023-10-20 10:22:12.729959\n",
      "First 17000 images copied at 2023-10-20 10:22:44.192840\n",
      "First 18000 images copied at 2023-10-20 10:23:20.188728\n",
      "First 19000 images copied at 2023-10-20 10:24:01.107701\n",
      "First 20000 images copied at 2023-10-20 10:24:46.884185\n",
      "First 21000 images copied at 2023-10-20 10:24:50.959426\n",
      "First 22000 images copied at 2023-10-20 10:24:58.239668\n",
      "First 23000 images copied at 2023-10-20 10:25:08.778394\n",
      "First 24000 images copied at 2023-10-20 10:25:26.023637\n",
      "First 25000 images copied at 2023-10-20 10:25:47.170083\n",
      "First 26000 images copied at 2023-10-20 10:26:11.861301\n",
      "First 27000 images copied at 2023-10-20 10:26:41.610010\n",
      "First 28000 images copied at 2023-10-20 10:27:15.623827\n",
      "First 29000 images copied at 2023-10-20 10:27:56.363692\n",
      "First 30000 images copied at 2023-10-20 10:28:43.154106\n",
      "First 31000 images copied at 2023-10-20 10:28:47.726254\n",
      "First 32000 images copied at 2023-10-20 10:28:53.810789\n",
      "First 33000 images copied at 2023-10-20 10:29:03.755353\n",
      "First 34000 images copied at 2023-10-20 10:29:18.004134\n",
      "First 35000 images copied at 2023-10-20 10:29:35.918811\n",
      "First 36000 images copied at 2023-10-20 10:29:58.756832\n",
      "First 37000 images copied at 2023-10-20 10:30:27.868827\n",
      "First 38000 images copied at 2023-10-20 10:31:02.973522\n",
      "First 39000 images copied at 2023-10-20 10:31:42.027160\n",
      "First 40000 images copied at 2023-10-20 10:32:24.358599\n",
      "First 41000 images copied at 2023-10-20 10:32:28.922953\n",
      "First 42000 images copied at 2023-10-20 10:32:34.752421\n",
      "First 43000 images copied at 2023-10-20 10:32:43.062201\n",
      "First 44000 images copied at 2023-10-20 10:32:55.092332\n",
      "First 45000 images copied at 2023-10-20 10:33:12.089866\n",
      "First 46000 images copied at 2023-10-20 10:33:35.150159\n",
      "First 47000 images copied at 2023-10-20 10:34:04.595332\n",
      "First 48000 images copied at 2023-10-20 10:34:37.881047\n",
      "First 49000 images copied at 2023-10-20 10:35:13.385567\n",
      "First 50000 images copied at 2023-10-20 10:35:56.726636\n",
      "First 51000 images copied at 2023-10-20 10:36:02.197783\n",
      "First 52000 images copied at 2023-10-20 10:36:08.475946\n",
      "First 53000 images copied at 2023-10-20 10:36:16.787381\n",
      "First 54000 images copied at 2023-10-20 10:36:28.400159\n",
      "First 55000 images copied at 2023-10-20 10:36:45.384483\n",
      "First 56000 images copied at 2023-10-20 10:37:07.599266\n",
      "First 57000 images copied at 2023-10-20 10:37:35.248254\n",
      "First 58000 images copied at 2023-10-20 10:38:07.723739\n",
      "First 59000 images copied at 2023-10-20 10:38:46.022760\n",
      "First 60000 images copied at 2023-10-20 10:39:27.593339\n",
      "First 61000 images copied at 2023-10-20 10:39:33.079033\n",
      "First 62000 images copied at 2023-10-20 10:39:39.599652\n",
      "First 63000 images copied at 2023-10-20 10:39:47.858010\n",
      "First 64000 images copied at 2023-10-20 10:40:00.000820\n",
      "First 65000 images copied at 2023-10-20 10:40:16.835286\n",
      "First 66000 images copied at 2023-10-20 10:40:38.724856\n",
      "First 67000 images copied at 2023-10-20 10:41:04.761998\n",
      "First 68000 images copied at 2023-10-20 10:41:36.396965\n",
      "First 69000 images copied at 2023-10-20 10:42:10.996558\n",
      "First 70000 images copied at 2023-10-20 10:42:53.387266\n",
      "First 71000 images copied at 2023-10-20 10:42:59.716567\n",
      "First 72000 images copied at 2023-10-20 10:43:07.344667\n",
      "First 73000 images copied at 2023-10-20 10:43:15.402447\n",
      "First 74000 images copied at 2023-10-20 10:43:26.347189\n",
      "First 75000 images copied at 2023-10-20 10:43:42.272132\n",
      "First 76000 images copied at 2023-10-20 10:44:02.175850\n",
      "First 77000 images copied at 2023-10-20 10:44:28.499126\n",
      "First 78000 images copied at 2023-10-20 10:45:00.030615\n",
      "First 79000 images copied at 2023-10-20 10:45:35.188497\n",
      "First 80000 images copied at 2023-10-20 10:46:17.288568\n",
      "First 81000 images copied at 2023-10-20 10:46:23.923947\n",
      "First 82000 images copied at 2023-10-20 10:46:31.789906\n",
      "First 83000 images copied at 2023-10-20 10:46:41.165264\n",
      "0:30:34.953354\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5359f813-59fc-40d4-8b8b-1e93a0b117dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'renaming_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#### Only renaming code\u001b[39;00m\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mrenaming_table\u001b[49m\u001b[38;5;241m.\u001b[39mapply(rename_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(end \u001b[38;5;241m-\u001b[39m start)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'renaming_table' is not defined"
     ]
    }
   ],
   "source": [
    "#### Only renaming code\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "renaming_table.apply(rename_images, axis=1)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
