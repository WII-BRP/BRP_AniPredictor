{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05571f6d-0dea-421e-bc4a-e44128759d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\05\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\06\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\07\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\08\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\09\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\10\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\11\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\12\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\13\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\14\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\15\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\16\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\17\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\18\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\19\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\20\n",
      "Loading Models...\n",
      "0:00:58\n",
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\05\n",
      "1783\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\05\\001_jpg_05_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 11.91 seconds\n",
      "\n",
      "Loaded model in 11.91 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [05:08<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "14/14 [==============================] - 11s 196ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 858/858 [00:02<00:00, 309.00it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 858/858 [00:03<00:00, 219.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 858 images copied and removed at 2024-01-14 15:47:07.954335\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 4s 276ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 534/534 [00:02<00:00, 259.68it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 534/534 [00:01<00:00, 365.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 534 images copied and removed at 2024-01-14 15:47:15.637667\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\06\n",
      "1705\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\06\\001_jpg_06_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.04 seconds\n",
      "\n",
      "Loaded model in 5.04 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:52<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "16/16 [==============================] - 3s 211ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 973/973 [00:02<00:00, 454.04it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 973/973 [00:01<00:00, 564.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 973 images copied and removed at 2024-01-14 15:52:23.030779\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 3s 206ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 907/907 [00:02<00:00, 373.55it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 907/907 [00:01<00:00, 525.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 907 images copied and removed at 2024-01-14 15:52:30.310901\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\07\n",
      "1705\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\07\\001_jpg_07_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 6.23 seconds\n",
      "\n",
      "Loaded model in 6.23 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:55<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:24<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "62/62 [==============================] - 10s 165ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|█████████████████████████████████████████████████████████████| 3923/3923 [00:15<00:00, 254.77it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 3923/3923 [00:03<00:00, 1284.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3923 images copied and removed at 2024-01-14 15:58:22.576302\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 9s 169ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|█████████████████████████████████████████████████████████████| 2982/2982 [00:05<00:00, 561.37it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 2982/2982 [00:02<00:00, 998.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2982 images copied and removed at 2024-01-14 15:58:40.300892\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\08\n",
      "1708\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\08\\001_jpg_08_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 4.79 seconds\n",
      "\n",
      "Loaded model in 4.79 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:54<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:26<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "61/61 [==============================] - 10s 166ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|█████████████████████████████████████████████████████████████| 3863/3863 [00:08<00:00, 437.10it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 3863/3863 [00:03<00:00, 1206.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3863 images copied and removed at 2024-01-14 16:04:26.698888\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 8s 170ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|█████████████████████████████████████████████████████████████| 2751/2751 [00:06<00:00, 456.71it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 2751/2751 [00:02<00:00, 1085.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2751 images copied and removed at 2024-01-14 16:04:43.476518\n",
      "Saving Logs\n",
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\09\n",
      "1705\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\09\\001_jpg_09_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 4.68 seconds\n",
      "\n",
      "Loaded model in 4.68 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:51<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [01:14<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "150/150 [==============================] - 24s 158ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|█████████████████████████████████████████████████████████████| 9548/9548 [00:24<00:00, 391.35it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 9548/9548 [00:06<00:00, 1489.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 9548 images copied and removed at 2024-01-14 16:11:48.459432\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 22s 159ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|█████████████████████████████████████████████████████████████| 8946/8946 [00:28<00:00, 316.93it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 8946/8946 [00:05<00:00, 1542.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 8946 images copied and removed at 2024-01-14 16:12:45.730630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\10\n",
      "1709\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\10\\001_jpg_10_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 4.97 seconds\n",
      "\n",
      "Loaded model in 4.97 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:50<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [01:30<00:00,  4.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "153/153 [==============================] - 24s 160ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|█████████████████████████████████████████████████████████████| 9753/9753 [00:37<00:00, 256.98it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 9753/9753 [00:43<00:00, 221.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 9753 images copied and removed at 2024-01-14 16:20:56.012191\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 20s 167ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|█████████████████████████████████████████████████████████████| 7812/7812 [01:13<00:00, 107.00it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 7812/7812 [00:53<00:00, 146.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 7812 images copied and removed at 2024-01-14 16:23:23.474021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\11\n",
      "1712\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\\11\\001_jpg_11_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 4.98 seconds\n",
      "\n",
      "Loaded model in 4.98 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████             | 84/100 [06:48<01:36,  6.02s/it]"
     ]
    }
   ],
   "source": [
    "### For internal drives\n",
    "\n",
    "from functions import *\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "try:\n",
    "    print(f\"Models loaded : {areModelsLoaded}\")\n",
    "except:\n",
    "    areModelsLoaded = False\n",
    "log = {}\n",
    "now = datetime.now()\n",
    "\n",
    "data = r\"F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\D2\\2023-05-27\\001\\jpg\"\n",
    "inp = \"YES\"\n",
    "\n",
    "## CHECK FOR GPU\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpu = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "\n",
    "if gpus:\n",
    "    print(\"GPU available\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n",
    "    \n",
    "## GET SUBDIRECTORIES\n",
    "\n",
    "sub_dirs = []\n",
    "for dirpath, dirnames, filenames in os.walk(data):\n",
    "    # if \"Cropped_images\" in dirpath:\n",
    "    #     continue\n",
    "    # if dirpath == data_dir and not filenames == []:\n",
    "    #     sub_dirs.append(dirpath)\n",
    "    if not \"Cropped_images\" in dirnames and not \"Cropped_images\" in dirpath and not data == dirpath:\n",
    "        sub_dirs.append(dirpath)\n",
    "        \n",
    "if sub_dirs == []:\n",
    "    sub_dirs.append(data)\n",
    "\n",
    "for i in sub_dirs:\n",
    "    print(i)\n",
    "#inp = input(\"Check Sub directories\")\n",
    "\n",
    "\n",
    "if inp == \"YES\":\n",
    "    ## LOAD MODELS\n",
    "    print(\"Loading Models...\")\n",
    "    order_level_class_names = [\"GIB\", \"Goat_Sheep\", \"Hare\", \"Human\", \"Raptor\", \"Small Bird\", \"Small Carnivore\", \"Ungulate\", \"Vehicle\", \"Wild Pig\"]\n",
    "    order_level_class_names.sort()\n",
    "    ungulate_class_names = [\"Camel\", \"Chinkara\", \"Nilgai\", \"Cattle\"]\n",
    "    ungulate_class_names.sort() \n",
    "    small_carnivores_class_names = [\"Dog\", \"Desert Cat\", \"Fox\"]\n",
    "    small_carnivores_class_names.sort()\n",
    "    \n",
    "    model_load_start=time.time()\n",
    "    if areModelsLoaded == False:\n",
    "        order_level_model_path = os.path.join(os.getcwd(), r\"Models\\Refined_Hierarchical.ckpt\")\n",
    "        order_level_model = tf.keras.models.load_model(order_level_model_path)\n",
    "        \n",
    "        ungulate_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Ungulates_3.ckpt\")\n",
    "        ungulate_model = tf.keras.models.load_model(ungulate_model_path)   \n",
    "        \n",
    "        small_carnivore_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Small_Carnivores_1.ckpt\")\n",
    "        small_carnivore_model= tf.keras.models.load_model(small_carnivore_model_path)\n",
    "        \n",
    "        areModelsLoaded = True\n",
    "        \n",
    "    model_load_end = time.time()\n",
    "    model_load_time = str(timedelta(seconds=round(model_load_end - model_load_start)))\n",
    "    log.update({\"Species Model Load Time\" : model_load_time})\n",
    "    print(model_load_time)\n",
    "    \n",
    "    for data_dir in sub_dirs:\n",
    "        print()\n",
    "        print(data_dir)\n",
    "        ## CREATE LOGS\n",
    "        \n",
    "        log.update({\"Run timestamp\" : str(now)})\n",
    "        # log.update({\"GPU\" : gpus})\n",
    "        log.update({\"GPU Available for Classification : \" : gpu_name})\n",
    "        # log.update({\"CPU\" : cpu})\n",
    "        num_images = 0\n",
    "        for root,dirs,files in os.walk(data_dir):\n",
    "            if not root == \"Cropped_images\":\n",
    "                num_images += len(files)\n",
    "                for f in files:\n",
    "                    if not f.endswith(\".jpg\"):\n",
    "                        num_images -= 1\n",
    "        log.update({\"Num images\" : num_images})\n",
    "        print(num_images)\n",
    "        \n",
    "        ## RUN MEGADETECTOR AND CREATE DETECTIONS.DF\n",
    "        \n",
    "        megadetector_start = time.time()\n",
    "        json_dir, megadetector_log = megadetector(data_dir, num_images)\n",
    "        if not megadetector_log == {}:\n",
    "            log.update(megadetector_log)\n",
    "        else:\n",
    "            megadetector_end = time.time()\n",
    "            megadetector_time = str(timedelta(seconds=round(megadetector_end - megadetector_start)))\n",
    "            log.update({\"Megadetector time\" : megadetector_time})\n",
    "            log.update({\"Megadetector Filename\" : os.path.basename(json_dir)})\n",
    "\n",
    "        df_detections = get_detection_df(data_dir, json_dir)\n",
    "        \n",
    "        ## CROP IMAGES\n",
    "        \n",
    "        cropping_start = time.time() \n",
    "        cropped_images = os.path.join(data_dir,r\"Cropped_images\\*\")\n",
    "        cropped_dir = clean_path(\"\\\\\".join(cropped_images.split(\"\\\\\")[:-1]))\n",
    "        if not os.path.exists(cropped_dir):\n",
    "            print(\"Cropping Images\")\n",
    "            df_crop = df_detections.copy()\n",
    "            df_crop[\"Cropped_image_directory\"] = cropped_dir\n",
    "            df_crop[\"Cropped_image_name\"] = df_crop[\"Filename\"] + \"_\" + df_crop[\"Detection_number\"].astype(str) + \".jpg\"\n",
    "            df_crop[\"Cropped_image_path\"] = (cropped_dir + \"\\\\\" + df_crop[\"Cropped_image_name\"]).apply(clean_path)\n",
    "            try:\n",
    "                df_crop=crop_images_batch_gpu(df_crop,512)\n",
    "            except:\n",
    "                df_crop = crop_images_batch(df_crop,512)\n",
    "                print(f\"Cropping exception occured\")\n",
    "        else:\n",
    "            print(\"Images already cropped...\")\n",
    "        cropping_end = time.time()\n",
    "        cropping_time = str(timedelta(seconds=round(cropping_end - cropping_start)))\n",
    "        log.update({\"Cropping Time\" : cropping_time})\n",
    "        log.update({\"Number of Detections\" : len(df_detections)})\n",
    "        \n",
    "        ## ORDER LEVEL PREDICTIONS\n",
    "        \n",
    "        order_level_start = time.time()\n",
    "        print(\"Predicting Order Level Classes...\")\n",
    "        df_temp, num_cropped = predict_lower_level_species(data_dir, \n",
    "                                                           r\"Cropped_images\\*\", \n",
    "                                                           order_level_class_names,\n",
    "                                                           order_level_model,\n",
    "                                                           level = \"Order\")\n",
    "        \n",
    "        order_level_end = time.time()\n",
    "        df_order = pd.merge(df_crop, df_temp, on='Cropped_image_name', how='left')\n",
    "        df_order[\"Order_pred\"] = df_order[\"Order_pred\"].fillna(\"Error\")\n",
    "        df_order[\"Order_dir\"] = (cropped_dir + \"\\\\\" + df_order[\"Order_pred\"]).apply(clean_path)\n",
    "        df_order[\"Order_level_path\"] = (df_order[\"Order_dir\"] + \"\\\\\" + df_order[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        unique_directories = set(df_order['Order_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Order Level Images...\")\n",
    "        #copy_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        #delete_images_batch(df_order[\"Cropped_image_path\"])\n",
    "        move_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        \n",
    "        order_shift_end = time.time()\n",
    "        order_pred_time = str(timedelta(seconds=round(order_level_end - order_level_start)))\n",
    "        order_shift_time = str(timedelta(seconds=round(order_shift_end - order_level_end)))\n",
    "        log.update({\"Order Level Prediction Time\" : order_shift_time})\n",
    "        log.update({\"Order Level Shifting Time\" : order_shift_time})\n",
    "        \n",
    "        \n",
    "        ## SMALL CARNIVORES PREDICT\n",
    "        small_carnivores_start = time.time()\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Small_Carnivore\")):\n",
    "            print(\"Predicting Small Carnivores...\")\n",
    "            df_small_carnivore, num_small_carnivores = predict_lower_level_species(cropped_dir, \n",
    "                                                                                   r\"Small Carnivore\\*\", \n",
    "                                                                                   small_carnivores_class_names,\n",
    "                                                                                   small_carnivore_model,\n",
    "                                                                                   level = \"Species\")\n",
    "            \n",
    "            small_carnivores_end = time.time()\n",
    "            small_carnivore_time = str(timedelta(seconds=round(small_carnivores_end - small_carnivores_start)))\n",
    "            log.update({\"Number of Small Carnivores Images\" : num_small_carnivores})\n",
    "            log.update({\"Small Carnivore Model Pred Time\" : small_carnivore_time})\n",
    "        else:\n",
    "            df_small_carnivore = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "       \n",
    "        ## UNGULATES PREDICT\n",
    "\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Ungulate\")):\n",
    "            ungulate_start = time.time()\n",
    "            print(\"Predicting Ungulates...\")\n",
    "            df_ungulate, num_ungulates = predict_lower_level_species(cropped_dir, \n",
    "                                                                     r\"Ungulate\\*\", \n",
    "                                                                     ungulate_class_names,\n",
    "                                                                     ungulate_model,\n",
    "                                                                     level = \"Species\")\n",
    "            \n",
    "            ungulate_end = time.time()\n",
    "            ungulate_time = str(timedelta(seconds=round(ungulate_end - ungulate_start)))\n",
    "            log.update({\"Number of Ungulates Images\" : num_ungulates})\n",
    "            log.update({\"Ungulate Model Pred Time\" : ungulate_time})\n",
    "        else:\n",
    "            df_ungulate = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "        \n",
    "        species_shift_start = time.time()\n",
    "        df_species = pd.concat([df_small_carnivore,df_ungulate])\n",
    "        df_species[\"Species_dir\"] = (cropped_dir + \"\\\\\" + df_species[\"Species_pred\"]).apply(clean_path)\n",
    "        df_species[\"Species_level_path\"] = (df_species[\"Species_dir\"] + \"\\\\\" + df_species[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        df_move = pd.merge(df_species, df_order, on='Cropped_image_name', how='left')\n",
    "        df_move = df_move[df_move[\"Order_level_path\"] != df_move[\"Species_level_path\"]]\n",
    "        unique_directories = set(df_move['Species_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Ungulates and Small Carnivores...\")\n",
    "        #copy_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        #delete_images_batch(df_move[\"Order_level_path\"])\n",
    "        move_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        \n",
    "        species_shift_end = time.time()\n",
    "        species_shift_time = str(timedelta(seconds=round(species_shift_end - species_shift_start)))\n",
    "        species_level_time = str(timedelta(seconds=round(species_shift_end - small_carnivores_start)))\n",
    "        log.update({\"Species Level Shift Imgs Time\" : species_shift_time})\n",
    "        log.update({\"Species Level Predict and Shift\" : species_level_time})\n",
    "        \n",
    "        ## SAVE FINAL PREDICTIONS.CSV\n",
    "        \n",
    "        df_final = pd.merge(df_order, df_species, on='Cropped_image_name', how='left')\n",
    "        df_final.drop(columns=['Order_dir', 'Order_level_path','Cropped_image_path'], inplace=True)\n",
    "        df_final_path = os.path.join(data_dir, \"predictions.csv\")\n",
    "        df_final.to_csv(df_final_path, index=False)\n",
    "        \n",
    "        ## SAVE LOG FILE\n",
    "        print(\"Saving Logs\")\n",
    "        log_file_name = \"_\".join(data_dir.split(\"\\\\\")[-3:])\n",
    "        log_file_path = os.path.join(data_dir, f\"{log_file_name}_log.json\")\n",
    "        with open(log_file_path, \"w\") as f:\n",
    "            json.dump(log, f, indent=2)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b994b27-e329-4f01-83bd-f974869d2d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded : True\n",
      "GPU available\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\05\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\06\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\07\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\08\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\09\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\10\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\11\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\12\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\13\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\14\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\15\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\16\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\17\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\18\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\19\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\20\n",
      "Loading Models...\n",
      "0:00:00\n",
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\05\n",
      "1783\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\05\\001_jpg_05_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 4.97 seconds\n",
      "\n",
      "Loaded model in 4.97 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:55<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "6/6 [==============================] - 1s 162ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 332/332 [00:01<00:00, 180.37it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 332/332 [00:01<00:00, 190.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 332 images copied and removed at 2024-01-13 23:18:51.477298\n",
      "Predicting Ungulates...\n",
      "1/5 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 203ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 183/183 [00:01<00:00, 120.40it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 183/183 [00:01<00:00, 127.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 183 images copied and removed at 2024-01-13 23:18:55.488082\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\06\n",
      "1699\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\06\\001_jpg_06_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 4.96 seconds\n",
      "\n",
      "Loaded model in 4.96 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:47<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "5/5 [==============================] - 2s 385ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 298/298 [00:01<00:00, 183.98it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 298/298 [00:01<00:00, 199.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 298 images copied and removed at 2024-01-13 23:23:50.269609\n",
      "Predicting Ungulates...\n",
      "1/5 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 175ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 286/286 [00:01<00:00, 177.66it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 286/286 [00:01<00:00, 197.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 286 images copied and removed at 2024-01-13 23:23:54.242850\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\07\n",
      "1709\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\07\\001_jpg_07_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.12 seconds\n",
      "\n",
      "Loaded model in 5.12 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:53<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "14/14 [==============================] - 3s 236ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 876/876 [00:03<00:00, 225.76it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 876/876 [00:01<00:00, 511.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 876 images copied and removed at 2024-01-13 23:29:03.965643\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 3s 235ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 640/640 [00:02<00:00, 238.79it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 640/640 [00:01<00:00, 380.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 640 images copied and removed at 2024-01-13 23:29:11.438509\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\08\n",
      "1709\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\08\\001_jpg_08_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.11 seconds\n",
      "\n",
      "Loaded model in 5.11 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [05:09<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "4/4 [==============================] - 2s 473ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 237/237 [00:01<00:00, 143.59it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 237/237 [00:01<00:00, 150.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 237 images copied and removed at 2024-01-13 23:34:28.645787\n",
      "Predicting Ungulates...\n",
      "1/3 [=========>....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 585ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████| 130/130 [00:01<00:00, 92.14it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 130/130 [00:01<00:00, 90.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 130 images copied and removed at 2024-01-13 23:34:32.815224\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\09\n",
      "1707\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\09\\001_jpg_09_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.21 seconds\n",
      "\n",
      "Loaded model in 5.21 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:50<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "5/5 [==============================] - 1s 175ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 275/275 [00:01<00:00, 171.75it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 275/275 [00:01<00:00, 173.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 275 images copied and removed at 2024-01-13 23:39:32.128298\n",
      "Predicting Ungulates...\n",
      "1/4 [======>.......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 513ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 217/217 [00:01<00:00, 129.82it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 217/217 [00:01<00:00, 150.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 217 images copied and removed at 2024-01-13 23:39:36.950034\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\10\n",
      "1705\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\10\\001_jpg_10_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.91 seconds\n",
      "\n",
      "Loaded model in 5.91 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:52<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "9/9 [==============================] - 2s 176ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 539/539 [00:02<00:00, 247.24it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 539/539 [00:01<00:00, 330.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 539 images copied and removed at 2024-01-13 23:44:40.838241\n",
      "Predicting Ungulates...\n",
      "1/5 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 198ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 281/281 [00:01<00:00, 173.40it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 281/281 [00:01<00:00, 189.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 281 images copied and removed at 2024-01-13 23:44:45.079536\n",
      "Saving Logs\n",
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\11\n",
      "1707\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\11\\001_jpg_11_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 4.89 seconds\n",
      "\n",
      "Loaded model in 4.89 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:50<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "11/11 [==============================] - 2s 176ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 672/672 [00:02<00:00, 236.64it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 672/672 [00:01<00:00, 399.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 672 images copied and removed at 2024-01-13 23:49:49.357414\n",
      "Predicting Ungulates...\n",
      "1/6 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 180ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 259/259 [00:01<00:00, 143.82it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 259/259 [00:01<00:00, 177.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 259 images copied and removed at 2024-01-13 23:49:53.718209\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\12\n",
      "1706\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\12\\001_jpg_12_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.81 seconds\n",
      "\n",
      "Loaded model in 5.82 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:52<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "6/6 [==============================] - 1s 164ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 340/340 [00:01<00:00, 185.75it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 340/340 [00:01<00:00, 219.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 340 images copied and removed at 2024-01-13 23:54:54.709769\n",
      "Predicting Ungulates...\n",
      "1/4 [======>.......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 563ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 208/208 [00:01<00:00, 141.47it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 208/208 [00:01<00:00, 137.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 208 images copied and removed at 2024-01-13 23:54:59.720863\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\13\n",
      "1706\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\13\\001_jpg_13_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.04 seconds\n",
      "\n",
      "Loaded model in 5.04 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:57<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "4/4 [==============================] - 2s 487ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 239/239 [00:01<00:00, 144.74it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 239/239 [00:33<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 239 images copied and removed at 2024-01-14 00:00:38.606186\n",
      "Predicting Ungulates...\n",
      "1/3 [=========>....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 765ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████| 123/123 [00:01<00:00, 84.84it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 123/123 [00:33<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 123 images copied and removed at 2024-01-14 00:01:15.241996\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\14\n",
      "1708\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\14\\001_jpg_14_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.42 seconds\n",
      "\n",
      "Loaded model in 5.42 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [05:06<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "6/6 [==============================] - 1s 164ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 363/363 [00:01<00:00, 184.28it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 363/363 [00:33<00:00, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 363 images copied and removed at 2024-01-14 00:07:02.997878\n",
      "Predicting Ungulates...\n",
      "1/6 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 186ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 224/224 [00:01<00:00, 133.36it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 224/224 [00:33<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 224 images copied and removed at 2024-01-14 00:07:39.393768\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\15\n",
      "1665\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\15\\001_jpg_15_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.38 seconds\n",
      "\n",
      "Loaded model in 5.38 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:54<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "4/4 [==============================] - 1s 457ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 228/228 [00:01<00:00, 142.49it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 228/228 [00:33<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 228 images copied and removed at 2024-01-14 00:13:14.584687\n",
      "Predicting Ungulates...\n",
      "1/4 [======>.......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 257ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 220/220 [00:01<00:00, 130.87it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 220/220 [00:33<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 220 images copied and removed at 2024-01-14 00:13:50.789375\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\16\n",
      "1647\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\16\\001_jpg_16_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.91 seconds\n",
      "\n",
      "Loaded model in 5.91 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:50<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "7/7 [==============================] - 1s 173ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 427/427 [00:02<00:00, 206.27it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 427/427 [00:33<00:00, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 427 images copied and removed at 2024-01-14 00:19:23.855408\n",
      "Predicting Ungulates...\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 200ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 402/402 [00:01<00:00, 203.09it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 402/402 [00:33<00:00, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 402 images copied and removed at 2024-01-14 00:20:00.938417\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\17\n",
      "1675\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\17\\001_jpg_17_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.56 seconds\n",
      "\n",
      "Loaded model in 5.56 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:47<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "3/3 [==============================] - 1s 495ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████| 138/138 [00:01<00:00, 96.42it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 138/138 [00:33<00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 138 images copied and removed at 2024-01-14 00:25:27.755442\n",
      "Predicting Ungulates...\n",
      "1/3 [=========>....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 315ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 88.78it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 127/127 [00:33<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 127 images copied and removed at 2024-01-14 00:26:03.550102\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\18\n",
      "1708\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\18\\001_jpg_18_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.41 seconds\n",
      "\n",
      "Loaded model in 5.41 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:55<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "1/1 [==============================] - 1s 740ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████████| 17/17 [00:01<00:00, 13.28it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████████████| 17/17 [00:33<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 17 images copied and removed at 2024-01-14 00:31:36.875784\n",
      "Predicting Ungulates...\n",
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.75it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████████████| 10/10 [00:33<00:00,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 10 images copied and removed at 2024-01-14 00:32:12.068878\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\19\n",
      "1737\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\19\\001_jpg_19_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.51 seconds\n",
      "\n",
      "Loaded model in 5.51 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [05:12<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "8/8 [==============================] - 2s 313ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 509/509 [00:02<00:00, 173.77it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 509/509 [00:33<00:00, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 509 images copied and removed at 2024-01-14 00:38:08.784943\n",
      "Predicting Ungulates...\n",
      "1/6 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 198ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|███████████████████████████████████████████████████████████████| 297/297 [00:01<00:00, 151.50it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████| 297/297 [00:33<00:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 297 images copied and removed at 2024-01-14 00:38:45.505634\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\20\n",
      "2\n",
      "Megadetector model\n",
      "Saving detections at F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\\20\\001_jpg_20_megadetector.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 5.32 seconds\n",
      "\n",
      "Loaded model in 5.32 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Boxes Created\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.63it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████████████| 2/2 [00:33<00:00, 16.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2 images copied and removed at 2024-01-14 00:39:36.704959\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 0it [00:01, ?it/s]\n",
      "Removing source images: 0it [00:01, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 0 images copied and removed at 2024-01-14 00:39:39.135406\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### For internal drives\n",
    "\n",
    "from functions import *\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "try:\n",
    "    print(f\"Models loaded : {areModelsLoaded}\")\n",
    "except:\n",
    "    areModelsLoaded = False\n",
    "log = {}\n",
    "now = datetime.now()\n",
    "\n",
    "data = r\"F:\\Guzzler_data\\2023\\CCTV\\SudasariACD\\C1\\2023-05-19\\001\\jpg\"\n",
    "inp = \"YES\"\n",
    "\n",
    "## CHECK FOR GPU\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpu = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "\n",
    "if gpus:\n",
    "    print(\"GPU available\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n",
    "    \n",
    "## GET SUBDIRECTORIES\n",
    "\n",
    "sub_dirs = []\n",
    "for dirpath, dirnames, filenames in os.walk(data):\n",
    "    # if \"Cropped_images\" in dirpath:\n",
    "    #     continue\n",
    "    # if dirpath == data_dir and not filenames == []:\n",
    "    #     sub_dirs.append(dirpath)\n",
    "    if not \"Cropped_images\" in dirnames and not \"Cropped_images\" in dirpath and not data == dirpath:\n",
    "        sub_dirs.append(dirpath)\n",
    "        \n",
    "if sub_dirs == []:\n",
    "    sub_dirs.append(data)\n",
    "\n",
    "for i in sub_dirs:\n",
    "    print(i)\n",
    "#inp = input(\"Check Sub directories\")\n",
    "\n",
    "\n",
    "if inp == \"YES\":\n",
    "    ## LOAD MODELS\n",
    "    print(\"Loading Models...\")\n",
    "    order_level_class_names = [\"GIB\", \"Goat_Sheep\", \"Hare\", \"Human\", \"Raptor\", \"Small Bird\", \"Small Carnivore\", \"Ungulate\", \"Vehicle\", \"Wild Pig\"]\n",
    "    order_level_class_names.sort()\n",
    "    ungulate_class_names = [\"Camel\", \"Chinkara\", \"Nilgai\", \"Cattle\"]\n",
    "    ungulate_class_names.sort() \n",
    "    small_carnivores_class_names = [\"Dog\", \"Desert Cat\", \"Fox\"]\n",
    "    small_carnivores_class_names.sort()\n",
    "    \n",
    "    model_load_start=time.time()\n",
    "    if areModelsLoaded == False:\n",
    "        order_level_model_path = os.path.join(os.getcwd(), r\"Models\\Refined_Hierarchical.ckpt\")\n",
    "        order_level_model = tf.keras.models.load_model(order_level_model_path)\n",
    "        \n",
    "        ungulate_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Ungulates_3.ckpt\")\n",
    "        ungulate_model = tf.keras.models.load_model(ungulate_model_path)   \n",
    "        \n",
    "        small_carnivore_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Small_Carnivores_1.ckpt\")\n",
    "        small_carnivore_model= tf.keras.models.load_model(small_carnivore_model_path)\n",
    "        \n",
    "        areModelsLoaded = True\n",
    "        \n",
    "    model_load_end = time.time()\n",
    "    model_load_time = str(timedelta(seconds=round(model_load_end - model_load_start)))\n",
    "    log.update({\"Species Model Load Time\" : model_load_time})\n",
    "    print(model_load_time)\n",
    "    \n",
    "    for data_dir in sub_dirs:\n",
    "        print()\n",
    "        print(data_dir)\n",
    "        ## CREATE LOGS\n",
    "        \n",
    "        log.update({\"Run timestamp\" : str(now)})\n",
    "        # log.update({\"GPU\" : gpus})\n",
    "        log.update({\"GPU Available for Classification : \" : gpu_name})\n",
    "        # log.update({\"CPU\" : cpu})\n",
    "        num_images = 0\n",
    "        for root,dirs,files in os.walk(data_dir):\n",
    "            if not root == \"Cropped_images\":\n",
    "                num_images += len(files)\n",
    "                for f in files:\n",
    "                    if not f.endswith(\".jpg\"):\n",
    "                        num_images -= 1\n",
    "        log.update({\"Num images\" : num_images})\n",
    "        print(num_images)\n",
    "        \n",
    "        ## RUN MEGADETECTOR AND CREATE DETECTIONS.DF\n",
    "        \n",
    "        megadetector_start = time.time()\n",
    "        json_dir, megadetector_log = megadetector(data_dir, num_images)\n",
    "        if not megadetector_log == {}:\n",
    "            log.update(megadetector_log)\n",
    "        else:\n",
    "            megadetector_end = time.time()\n",
    "            megadetector_time = str(timedelta(seconds=round(megadetector_end - megadetector_start)))\n",
    "            log.update({\"Megadetector time\" : megadetector_time})\n",
    "            log.update({\"Megadetector Filename\" : os.path.basename(json_dir)})\n",
    "\n",
    "        df_detections = get_detection_df(data_dir, json_dir)\n",
    "        \n",
    "        ## CROP IMAGES\n",
    "        \n",
    "        cropping_start = time.time() \n",
    "        cropped_images = os.path.join(data_dir,r\"Cropped_images\\*\")\n",
    "        cropped_dir = clean_path(\"\\\\\".join(cropped_images.split(\"\\\\\")[:-1]))\n",
    "        if not os.path.exists(cropped_dir):\n",
    "            print(\"Cropping Images\")\n",
    "            df_crop = df_detections.copy()\n",
    "            df_crop[\"Cropped_image_directory\"] = cropped_dir\n",
    "            df_crop[\"Cropped_image_name\"] = df_crop[\"Filename\"] + \"_\" + df_crop[\"Detection_number\"].astype(str) + \".jpg\"\n",
    "            df_crop[\"Cropped_image_path\"] = (cropped_dir + \"\\\\\" + df_crop[\"Cropped_image_name\"]).apply(clean_path)\n",
    "            try:\n",
    "                df_crop=crop_images_batch_gpu(df_crop,512)\n",
    "            except:\n",
    "                print(f\"Cropping exception occured\")\n",
    "        else:\n",
    "            print(\"Images already cropped...\")\n",
    "        cropping_end = time.time()\n",
    "        cropping_time = str(timedelta(seconds=round(cropping_end - cropping_start)))\n",
    "        log.update({\"Cropping Time\" : cropping_time})\n",
    "        log.update({\"Number of Detections\" : len(df_detections)})\n",
    "        \n",
    "        ## ORDER LEVEL PREDICTIONS\n",
    "        \n",
    "        order_level_start = time.time()\n",
    "        print(\"Predicting Order Level Classes...\")\n",
    "        df_temp, num_cropped = predict_lower_level_species(data_dir, \n",
    "                                                           r\"Cropped_images\\*\", \n",
    "                                                           order_level_class_names,\n",
    "                                                           order_level_model,\n",
    "                                                           level = \"Order\")\n",
    "        \n",
    "        order_level_end = time.time()\n",
    "        df_order = pd.merge(df_crop, df_temp, on='Cropped_image_name', how='left')\n",
    "        df_order[\"Order_pred\"] = df_order[\"Order_pred\"].fillna(\"Error\")\n",
    "        df_order[\"Order_dir\"] = (cropped_dir + \"\\\\\" + df_order[\"Order_pred\"]).apply(clean_path)\n",
    "        df_order[\"Order_level_path\"] = (df_order[\"Order_dir\"] + \"\\\\\" + df_order[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        unique_directories = set(df_order['Order_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Order Level Images...\")\n",
    "        #copy_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        #delete_images_batch(df_order[\"Cropped_image_path\"])\n",
    "        move_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        \n",
    "        order_shift_end = time.time()\n",
    "        order_pred_time = str(timedelta(seconds=round(order_level_end - order_level_start)))\n",
    "        order_shift_time = str(timedelta(seconds=round(order_shift_end - order_level_end)))\n",
    "        log.update({\"Order Level Prediction Time\" : order_shift_time})\n",
    "        log.update({\"Order Level Shifting Time\" : order_shift_time})\n",
    "        \n",
    "        \n",
    "        ## SMALL CARNIVORES PREDICT\n",
    "        small_carnivores_start = time.time()\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Small_Carnivore\")):\n",
    "            print(\"Predicting Small Carnivores...\")\n",
    "            df_small_carnivore, num_small_carnivores = predict_lower_level_species(cropped_dir, \n",
    "                                                                                   r\"Small Carnivore\\*\", \n",
    "                                                                                   small_carnivores_class_names,\n",
    "                                                                                   small_carnivore_model,\n",
    "                                                                                   level = \"Species\")\n",
    "            \n",
    "            small_carnivores_end = time.time()\n",
    "            small_carnivore_time = str(timedelta(seconds=round(small_carnivores_end - small_carnivores_start)))\n",
    "            log.update({\"Number of Small Carnivores Images\" : num_small_carnivores})\n",
    "            log.update({\"Small Carnivore Model Pred Time\" : small_carnivore_time})\n",
    "        else:\n",
    "            df_small_carnivore = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "       \n",
    "        ## UNGULATES PREDICT\n",
    "\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Ungulate\")):\n",
    "            ungulate_start = time.time()\n",
    "            print(\"Predicting Ungulates...\")\n",
    "            df_ungulate, num_ungulates = predict_lower_level_species(cropped_dir, \n",
    "                                                                     r\"Ungulate\\*\", \n",
    "                                                                     ungulate_class_names,\n",
    "                                                                     ungulate_model,\n",
    "                                                                     level = \"Species\")\n",
    "            \n",
    "            ungulate_end = time.time()\n",
    "            ungulate_time = str(timedelta(seconds=round(ungulate_end - ungulate_start)))\n",
    "            log.update({\"Number of Ungulates Images\" : num_ungulates})\n",
    "            log.update({\"Ungulate Model Pred Time\" : ungulate_time})\n",
    "        else:\n",
    "            df_ungulate = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "        \n",
    "        species_shift_start = time.time()\n",
    "        df_species = pd.concat([df_small_carnivore,df_ungulate])\n",
    "        df_species[\"Species_dir\"] = (cropped_dir + \"\\\\\" + df_species[\"Species_pred\"]).apply(clean_path)\n",
    "        df_species[\"Species_level_path\"] = (df_species[\"Species_dir\"] + \"\\\\\" + df_species[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        df_move = pd.merge(df_species, df_order, on='Cropped_image_name', how='left')\n",
    "        df_move = df_move[df_move[\"Order_level_path\"] != df_move[\"Species_level_path\"]]\n",
    "        unique_directories = set(df_move['Species_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Ungulates and Small Carnivores...\")\n",
    "        #copy_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        #delete_images_batch(df_move[\"Order_level_path\"])\n",
    "        move_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        \n",
    "        species_shift_end = time.time()\n",
    "        species_shift_time = str(timedelta(seconds=round(species_shift_end - species_shift_start)))\n",
    "        species_level_time = str(timedelta(seconds=round(species_shift_end - small_carnivores_start)))\n",
    "        log.update({\"Species Level Shift Imgs Time\" : species_shift_time})\n",
    "        log.update({\"Species Level Predict and Shift\" : species_level_time})\n",
    "        \n",
    "        ## SAVE FINAL PREDICTIONS.CSV\n",
    "        \n",
    "        df_final = pd.merge(df_order, df_species, on='Cropped_image_name', how='left')\n",
    "        df_final.drop(columns=['Order_dir', 'Order_level_path','Cropped_image_path'], inplace=True)\n",
    "        df_final_path = os.path.join(data_dir, \"predictions.csv\")\n",
    "        df_final.to_csv(df_final_path, index=False)\n",
    "        \n",
    "        ## SAVE LOG FILE\n",
    "        print(\"Saving Logs\")\n",
    "        log_file_name = \"_\".join(data_dir.split(\"\\\\\")[-3:])\n",
    "        log_file_path = os.path.join(data_dir, f\"{log_file_name}_log.json\")\n",
    "        with open(log_file_path, \"w\") as f:\n",
    "            json.dump(log, f, indent=2)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2fff07-abe0-4d3b-aff9-e18a574ebf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded : True\n",
      "GPU available\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\10\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\11\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\12\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\13\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\14\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\15\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\16\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\17\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\18\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\19\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\20\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\21\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\22\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\23\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\24\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\25\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\26\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\27\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\28\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\29\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\3\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\30\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\31\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\32\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\5\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\6\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\7\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\8\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\9\n",
      "Loading Models...\n",
      "0:00:00\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\10\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 103/103 [20:35<00:00, 12.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "831/831 [==============================] - 127s 153ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 53177/53177 [15:52<00:00, 55.83it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 53177/53177 [00:34<00:00, 1560.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 53177 images copied and removed at 2023-11-24 01:00:10.480285\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738/738 [==============================] - 113s 153ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 33640/33640 [11:40<00:00, 48.05it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 33640/33640 [00:20<00:00, 1644.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 33640 images copied and removed at 2023-11-24 01:14:07.539564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\11\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [21:20<00:00, 16.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "644/644 [==============================] - 97s 151ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 41171/41171 [16:02<00:00, 42.77it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 41171/41171 [00:25<00:00, 1594.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 41171 images copied and removed at 2023-11-24 01:53:48.175225\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601/601 [==============================] - 91s 152ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 24977/24977 [10:22<00:00, 40.11it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 24977/24977 [00:15<00:00, 1648.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 24977 images copied and removed at 2023-11-24 02:06:00.281370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\12\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [12:04<00:00, 17.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "335/335 [==============================] - 51s 152ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 21399/21399 [09:29<00:00, 37.60it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 21399/21399 [00:12<00:00, 1697.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 21399 images copied and removed at 2023-11-24 02:28:56.182866\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 25s 160ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 7098/7098 [03:14<00:00, 36.42it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 7098/7098 [00:04<00:00, 1556.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 7098 images copied and removed at 2023-11-24 02:32:41.348839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\13\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [11:29<00:00, 19.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "296/296 [==============================] - 46s 154ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 18893/18893 [09:06<00:00, 34.59it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 18893/18893 [00:11<00:00, 1681.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 18893 images copied and removed at 2023-11-24 02:54:35.620453\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 11s 164ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 3309/3309 [01:38<00:00, 33.49it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 3309/3309 [00:03<00:00, 1085.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3309 images copied and removed at 2023-11-24 02:56:29.531230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\14\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [10:47<00:00, 20.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "264/264 [==============================] - 41s 154ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 16844/16844 [08:39<00:00, 32.45it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 16844/16844 [00:09<00:00, 1713.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 16844 images copied and removed at 2023-11-24 03:17:08.937454\n",
      "Predicting Ungulates...\n",
      "117/117 [==============================] - 18s 155ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 5031/5031 [02:38<00:00, 31.71it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 5031/5031 [00:03<00:00, 1453.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 5031 images copied and removed at 2023-11-24 03:20:09.888146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\15\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [06:02<00:00, 21.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "142/142 [==============================] - 22s 153ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 9083/9083 [04:46<00:00, 31.74it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 9083/9083 [00:05<00:00, 1597.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 9083 images copied and removed at 2023-11-24 03:31:45.337905\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 7s 155ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 2167/2167 [01:08<00:00, 31.67it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 2167/2167 [00:02<00:00, 982.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2167 images copied and removed at 2023-11-24 03:33:03.547911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\16\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [03:46<00:00, 20.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "92/92 [==============================] - 15s 160ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 5846/5846 [03:05<00:00, 31.51it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 5846/5846 [00:04<00:00, 1396.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 5846 images copied and removed at 2023-11-24 03:40:27.458695\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 5s 181ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 1413/1413 [00:46<00:00, 30.63it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 1413/1413 [00:01<00:00, 750.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1413 images copied and removed at 2023-11-24 03:41:21.068245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\17\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [04:56<00:00, 21.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "115/115 [==============================] - 18s 153ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 7312/7312 [03:58<00:00, 30.71it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 7312/7312 [00:05<00:00, 1452.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 7312 images copied and removed at 2023-11-24 03:50:47.958713\n",
      "Predicting Ungulates...\n",
      "1/5 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 420ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████| 223/223 [00:08<00:00, 26.20it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 223/223 [00:01<00:00, 169.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 223 images copied and removed at 2023-11-24 03:50:59.708916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\18\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [05:22<00:00, 21.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "126/126 [==============================] - 19s 152ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 8018/8018 [04:27<00:00, 29.97it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 8018/8018 [00:05<00:00, 1509.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 8018 images copied and removed at 2023-11-24 04:01:32.446941\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 3s 205ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████| 716/716 [00:25<00:00, 27.90it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 716/716 [00:01<00:00, 467.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 716 images copied and removed at 2023-11-24 04:02:02.799550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\19\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [07:24<00:00, 22.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "162/162 [==============================] - 25s 152ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 10306/10306 [05:54<00:00, 29.07it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 10306/10306 [00:06<00:00, 1608.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 10306 images copied and removed at 2023-11-24 04:16:00.790019\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 3s 223ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████| 843/843 [00:30<00:00, 27.65it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 843/843 [00:01<00:00, 523.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 843 images copied and removed at 2023-11-24 04:16:36.319543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\20\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [06:22<00:00, 22.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "143/143 [==============================] - 22s 153ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 9124/9124 [05:15<00:00, 28.88it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 9124/9124 [00:05<00:00, 1529.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 9124 images copied and removed at 2023-11-24 04:29:04.860550\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 4s 159ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 1300/1300 [00:46<00:00, 27.93it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 1300/1300 [00:01<00:00, 723.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1300 images copied and removed at 2023-11-24 04:29:57.347624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\21\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [05:21<00:00, 22.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "117/117 [==============================] - 18s 154ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 7468/7468 [04:23<00:00, 28.29it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 7468/7468 [00:04<00:00, 1499.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 7468 images copied and removed at 2023-11-24 04:40:22.373159\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 201ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 1171/1171 [00:42<00:00, 27.26it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 1171/1171 [00:01<00:00, 683.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1171 images copied and removed at 2023-11-24 04:41:11.816906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\22\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:56<00:00, 23.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "43/43 [==============================] - 7s 158ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 2709/2709 [01:38<00:00, 27.64it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 2709/2709 [00:02<00:00, 1000.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2709 images copied and removed at 2023-11-24 04:45:06.316937\n",
      "Predicting Ungulates...\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 183ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████| 314/314 [00:12<00:00, 24.97it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 314/314 [00:01<00:00, 212.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 314 images copied and removed at 2023-11-24 04:45:21.690385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\23\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [08:53<00:00, 23.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "186/186 [==============================] - 29s 156ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 11845/11845 [07:15<00:00, 27.17it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 11845/11845 [00:06<00:00, 1693.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 11845 images copied and removed at 2023-11-24 05:02:14.546706\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 13s 166ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 4405/4405 [02:45<00:00, 26.61it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 4405/4405 [00:03<00:00, 1328.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 4405 images copied and removed at 2023-11-24 05:05:16.497667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\24\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [06:28<00:00, 24.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "132/132 [==============================] - 21s 160ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 8421/8421 [05:19<00:00, 26.35it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 8421/8421 [00:05<00:00, 1495.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 8421 images copied and removed at 2023-11-24 05:17:45.724954\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 10s 168ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 2436/2436 [01:34<00:00, 25.78it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 2436/2436 [00:02<00:00, 1055.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2436 images copied and removed at 2023-11-24 05:19:33.395734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\25\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:15<00:00, 25.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "28/28 [==============================] - 4s 162ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 1764/1764 [01:08<00:00, 25.59it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 1764/1764 [00:01<00:00, 895.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1764 images copied and removed at 2023-11-24 05:22:18.265604\n",
      "Predicting Ungulates...\n",
      " 1/13 [=>............................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 3s 251ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████| 578/578 [00:23<00:00, 24.57it/s]\n",
      "Removing source images: 100%|███████████████████████████████████████████████████████| 578/578 [00:01<00:00, 344.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 578 images copied and removed at 2023-11-24 05:22:46.745019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\26\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:30<00:00, 25.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "53/53 [==============================] - 8s 153ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 3373/3373 [02:14<00:00, 25.02it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 3373/3373 [00:03<00:00, 1100.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3373 images copied and removed at 2023-11-24 05:28:00.942343\n",
      "Predicting Ungulates...\n",
      "1/3 [=========>....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 688ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████████| 94/94 [00:05<00:00, 18.24it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████████████| 94/94 [00:01<00:00, 75.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 94 images copied and removed at 2023-11-24 05:28:08.932131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\27\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:09<00:00, 25.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "45/45 [==============================] - 7s 156ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 2880/2880 [01:56<00:00, 24.70it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 2880/2880 [00:02<00:00, 1147.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2880 images copied and removed at 2023-11-24 05:32:43.768907\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 160ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 1203/1203 [00:49<00:00, 24.22it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 1203/1203 [00:01<00:00, 641.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1203 images copied and removed at 2023-11-24 05:33:41.061955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\28\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [05:54<00:00, 25.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "114/114 [==============================] - 17s 153ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 7268/7268 [04:56<00:00, 24.49it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 7268/7268 [00:04<00:00, 1504.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 7268 images copied and removed at 2023-11-24 05:45:03.515780\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 8s 182ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 1734/1734 [01:12<00:00, 23.91it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 1734/1734 [00:02<00:00, 865.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1734 images copied and removed at 2023-11-24 05:46:25.922489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\29\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [09:04<00:00, 25.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "174/174 [==============================] - 27s 157ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 11128/11128 [07:47<00:00, 23.81it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 11128/11128 [00:06<00:00, 1600.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 11128 images copied and removed at 2023-11-24 06:04:14.932956\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 7s 157ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 1820/1820 [01:18<00:00, 23.17it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 1820/1820 [00:02<00:00, 867.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1820 images copied and removed at 2023-11-24 06:05:43.185644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\3\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [30:55<00:00, 26.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "559/559 [==============================] - 85s 151ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 35744/35744 [26:19<00:00, 22.64it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 35744/35744 [00:22<00:00, 1616.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 35744 images copied and removed at 2023-11-24 07:05:14.107802\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 58s 152ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 17037/17037 [12:56<00:00, 21.93it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 17037/17037 [00:10<00:00, 1627.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 17037 images copied and removed at 2023-11-24 07:19:21.274223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\30\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [04:39<00:00, 27.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "88/88 [==============================] - 13s 153ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 5625/5625 [04:27<00:00, 21.04it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 5625/5625 [00:03<00:00, 1412.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 5625 images copied and removed at 2023-11-24 07:29:16.787648\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 6s 158ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 1909/1909 [01:32<00:00, 20.64it/s]\n",
      "Removing source images: 100%|█████████████████████████████████████████████████████| 1909/1909 [00:02<00:00, 878.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 1909 images copied and removed at 2023-11-24 07:30:57.687600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\31\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [06:32<00:00, 28.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "114/114 [==============================] - 18s 158ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 7239/7239 [05:48<00:00, 20.76it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 7239/7239 [00:04<00:00, 1495.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 7239 images copied and removed at 2023-11-24 07:43:51.348492\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 9s 156ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 2900/2900 [02:21<00:00, 20.52it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 2900/2900 [00:02<00:00, 1169.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2900 images copied and removed at 2023-11-24 07:46:24.284446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\32\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [11:39<00:00, 31.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "181/181 [==============================] - 28s 155ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 11529/11529 [08:53<00:00, 21.60it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 11529/11529 [00:07<00:00, 1607.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 11529 images copied and removed at 2023-11-24 08:07:53.798961\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 22s 157ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 5527/5527 [04:18<00:00, 21.35it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 5527/5527 [00:03<00:00, 1447.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 5527 images copied and removed at 2023-11-24 08:12:38.808498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\5\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [33:06<00:00, 29.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "550/550 [==============================] - 83s 152ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 35177/35177 [28:21<00:00, 20.68it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 35177/35177 [00:22<00:00, 1595.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 35177 images copied and removed at 2023-11-24 09:16:19.407232\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 51s 152ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 16178/16178 [13:37<00:00, 19.79it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 16178/16178 [00:10<00:00, 1608.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 16178 images copied and removed at 2023-11-24 09:30:59.796712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\6\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [39:01<00:00, 31.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "593/593 [==============================] - 91s 153ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 37923/37923 [33:55<00:00, 18.63it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 37923/37923 [00:26<00:00, 1425.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 37923 images copied and removed at 2023-11-24 10:46:06.963322\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 53s 152ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 17479/17479 [16:01<00:00, 18.17it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 17479/17479 [00:11<00:00, 1568.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 17479 images copied and removed at 2023-11-24 11:03:15.173262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\7\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [33:12<00:00, 34.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "471/471 [==============================] - 72s 152ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 30132/30132 [28:56<00:00, 17.35it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 30132/30132 [00:19<00:00, 1526.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 30132 images copied and removed at 2023-11-24 12:07:34.330972\n",
      "Predicting Ungulates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/355 [==============================] - 54s 152ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 16428/16428 [16:05<00:00, 17.02it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 16428/16428 [00:10<00:00, 1636.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 16428 images copied and removed at 2023-11-24 12:24:45.821264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Logs\n",
      "\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\8\n",
      "0\n",
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 36/60 [21:57<14:41, 36.75s/it]"
     ]
    }
   ],
   "source": [
    "### For internal drives\n",
    "\n",
    "from functions import *\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "try:\n",
    "    print(f\"Models loaded : {areModelsLoaded}\")\n",
    "except:\n",
    "    areModelsLoaded = False\n",
    "log = {}\n",
    "now = datetime.now()\n",
    "\n",
    "data = r\"E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\"\n",
    "inp = \"YES\"\n",
    "\n",
    "## CHECK FOR GPU\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpu = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "\n",
    "if gpus:\n",
    "    print(\"GPU available\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n",
    "    \n",
    "## GET SUBDIRECTORIES\n",
    "\n",
    "sub_dirs = []\n",
    "for dirpath, dirnames, filenames in os.walk(data):\n",
    "    # if \"Cropped_images\" in dirpath:\n",
    "    #     continue\n",
    "    # if dirpath == data_dir and not filenames == []:\n",
    "    #     sub_dirs.append(dirpath)\n",
    "    if not \"Cropped_images\" in dirnames and not \"Cropped_images\" in dirpath and not data == dirpath:\n",
    "        sub_dirs.append(dirpath)\n",
    "        \n",
    "if sub_dirs == []:\n",
    "    sub_dirs.append(data)\n",
    "\n",
    "for i in sub_dirs:\n",
    "    print(i)\n",
    "#inp = input(\"Check Sub directories\")\n",
    "\n",
    "\n",
    "if inp == \"YES\":\n",
    "    ## LOAD MODELS\n",
    "    print(\"Loading Models...\")\n",
    "    order_level_class_names = [\"GIB\", \"Goat_Sheep\", \"Hare\", \"Human\", \"Raptor\", \"Small Bird\", \"Small Carnivore\", \"Ungulate\", \"Vehicle\", \"Wild Pig\"]\n",
    "    order_level_class_names.sort()\n",
    "    ungulate_class_names = [\"Camel\", \"Chinkara\", \"Nilgai\", \"Cattle\"]\n",
    "    ungulate_class_names.sort() \n",
    "    small_carnivores_class_names = [\"Dog\", \"Desert Cat\", \"Fox\"]\n",
    "    small_carnivores_class_names.sort()\n",
    "    \n",
    "    model_load_start=time.time()\n",
    "    if areModelsLoaded == False:\n",
    "        order_level_model_path = os.path.join(os.getcwd(), r\"Models\\Refined_Hierarchical.ckpt\")\n",
    "        order_level_model = tf.keras.models.load_model(order_level_model_path)\n",
    "        \n",
    "        ungulate_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Ungulates_3.ckpt\")\n",
    "        ungulate_model = tf.keras.models.load_model(ungulate_model_path)   \n",
    "        \n",
    "        small_carnivore_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Small_Carnivores_1.ckpt\")\n",
    "        small_carnivore_model= tf.keras.models.load_model(small_carnivore_model_path)\n",
    "        \n",
    "        areModelsLoaded = True\n",
    "        \n",
    "    model_load_end = time.time()\n",
    "    model_load_time = str(timedelta(seconds=round(model_load_end - model_load_start)))\n",
    "    log.update({\"Species Model Load Time\" : model_load_time})\n",
    "    print(model_load_time)\n",
    "    \n",
    "    for data_dir in sub_dirs:\n",
    "        print()\n",
    "        print(data_dir)\n",
    "        ## CREATE LOGS\n",
    "        \n",
    "        log.update({\"Run timestamp\" : str(now)})\n",
    "        # log.update({\"GPU\" : gpus})\n",
    "        log.update({\"GPU Available for Classification : \" : gpu_name})\n",
    "        # log.update({\"CPU\" : cpu})\n",
    "        num_images = 0\n",
    "        for root,dirs,files in os.walk(data_dir):\n",
    "            if not root == \"Cropped_images\":\n",
    "                num_images += len(files)\n",
    "                for f in files:\n",
    "                    if not f.endswith(\".jpg\"):\n",
    "                        num_images -= 1\n",
    "        log.update({\"Num images\" : num_images})\n",
    "        print(num_images)\n",
    "        \n",
    "        ## RUN MEGADETECTOR AND CREATE DETECTIONS.DF\n",
    "        \n",
    "        megadetector_start = time.time()\n",
    "        json_dir, megadetector_log = megadetector(data_dir, num_images)\n",
    "        if not megadetector_log == {}:\n",
    "            log.update(megadetector_log)\n",
    "        else:\n",
    "            megadetector_end = time.time()\n",
    "            megadetector_time = str(timedelta(seconds=round(megadetector_end - megadetector_start)))\n",
    "            log.update({\"Megadetector time\" : megadetector_time})\n",
    "            log.update({\"Megadetector Filename\" : os.path.basename(json_dir)})\n",
    "\n",
    "        df_detections = get_detection_df(data_dir, json_dir)\n",
    "        \n",
    "        ## CROP IMAGES\n",
    "        \n",
    "        cropping_start = time.time() \n",
    "        cropped_images = os.path.join(data_dir,r\"Cropped_images\\*\")\n",
    "        cropped_dir = clean_path(\"\\\\\".join(cropped_images.split(\"\\\\\")[:-1]))\n",
    "        if not os.path.exists(cropped_dir):\n",
    "            print(\"Cropping Images\")\n",
    "            df_crop = df_detections.copy()\n",
    "            df_crop[\"Cropped_image_directory\"] = cropped_dir\n",
    "            df_crop[\"Cropped_image_name\"] = df_crop[\"Filename\"] + \"_\" + df_crop[\"Detection_number\"].astype(str) + \".jpg\"\n",
    "            df_crop[\"Cropped_image_path\"] = (cropped_dir + \"\\\\\" + df_crop[\"Cropped_image_name\"]).apply(clean_path)\n",
    "            try:\n",
    "                df_crop=crop_images_batch_gpu(df_crop,512)\n",
    "            except:\n",
    "                print(f\"Cropping exception occured\")\n",
    "        else:\n",
    "            print(\"Images already cropped...\")\n",
    "        cropping_end = time.time()\n",
    "        cropping_time = str(timedelta(seconds=round(cropping_end - cropping_start)))\n",
    "        log.update({\"Cropping Time\" : cropping_time})\n",
    "        log.update({\"Number of Detections\" : len(df_detections)})\n",
    "        \n",
    "        ## ORDER LEVEL PREDICTIONS\n",
    "        \n",
    "        order_level_start = time.time()\n",
    "        print(\"Predicting Order Level Classes...\")\n",
    "        df_temp, num_cropped = predict_lower_level_species(data_dir, \n",
    "                                                           r\"Cropped_images\\*\", \n",
    "                                                           order_level_class_names,\n",
    "                                                           order_level_model,\n",
    "                                                           level = \"Order\")\n",
    "        \n",
    "        order_level_end = time.time()\n",
    "        df_order = pd.merge(df_crop, df_temp, on='Cropped_image_name', how='left')\n",
    "        df_order[\"Order_pred\"] = df_order[\"Order_pred\"].fillna(\"Error\")\n",
    "        df_order[\"Order_dir\"] = (cropped_dir + \"\\\\\" + df_order[\"Order_pred\"]).apply(clean_path)\n",
    "        df_order[\"Order_level_path\"] = (df_order[\"Order_dir\"] + \"\\\\\" + df_order[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        unique_directories = set(df_order['Order_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Order Level Images...\")\n",
    "        #copy_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        #delete_images_batch(df_order[\"Cropped_image_path\"])\n",
    "        move_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        \n",
    "        order_shift_end = time.time()\n",
    "        order_pred_time = str(timedelta(seconds=round(order_level_end - order_level_start)))\n",
    "        order_shift_time = str(timedelta(seconds=round(order_shift_end - order_level_end)))\n",
    "        log.update({\"Order Level Prediction Time\" : order_shift_time})\n",
    "        log.update({\"Order Level Shifting Time\" : order_shift_time})\n",
    "        \n",
    "        \n",
    "        ## SMALL CARNIVORES PREDICT\n",
    "        small_carnivores_start = time.time()\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Small_Carnivore\")):\n",
    "            print(\"Predicting Small Carnivores...\")\n",
    "            df_small_carnivore, num_small_carnivores = predict_lower_level_species(cropped_dir, \n",
    "                                                                                   r\"Small Carnivore\\*\", \n",
    "                                                                                   small_carnivores_class_names,\n",
    "                                                                                   small_carnivore_model,\n",
    "                                                                                   level = \"Species\")\n",
    "            \n",
    "            small_carnivores_end = time.time()\n",
    "            small_carnivore_time = str(timedelta(seconds=round(small_carnivores_end - small_carnivores_start)))\n",
    "            log.update({\"Number of Small Carnivores Images\" : num_small_carnivores})\n",
    "            log.update({\"Small Carnivore Model Pred Time\" : small_carnivore_time})\n",
    "        else:\n",
    "            df_small_carnivore = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "       \n",
    "        ## UNGULATES PREDICT\n",
    "\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Ungulate\")):\n",
    "            ungulate_start = time.time()\n",
    "            print(\"Predicting Ungulates...\")\n",
    "            df_ungulate, num_ungulates = predict_lower_level_species(cropped_dir, \n",
    "                                                                     r\"Ungulate\\*\", \n",
    "                                                                     ungulate_class_names,\n",
    "                                                                     ungulate_model,\n",
    "                                                                     level = \"Species\")\n",
    "            \n",
    "            ungulate_end = time.time()\n",
    "            ungulate_time = str(timedelta(seconds=round(ungulate_end - ungulate_start)))\n",
    "            log.update({\"Number of Ungulates Images\" : num_ungulates})\n",
    "            log.update({\"Ungulate Model Pred Time\" : ungulate_time})\n",
    "        else:\n",
    "            df_ungulate = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "        \n",
    "        species_shift_start = time.time()\n",
    "        df_species = pd.concat([df_small_carnivore,df_ungulate])\n",
    "        df_species[\"Species_dir\"] = (cropped_dir + \"\\\\\" + df_species[\"Species_pred\"]).apply(clean_path)\n",
    "        df_species[\"Species_level_path\"] = (df_species[\"Species_dir\"] + \"\\\\\" + df_species[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        df_move = pd.merge(df_species, df_order, on='Cropped_image_name', how='left')\n",
    "        df_move = df_move[df_move[\"Order_level_path\"] != df_move[\"Species_level_path\"]]\n",
    "        unique_directories = set(df_move['Species_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Ungulates and Small Carnivores...\")\n",
    "        #copy_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        #delete_images_batch(df_move[\"Order_level_path\"])\n",
    "        move_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        \n",
    "        species_shift_end = time.time()\n",
    "        species_shift_time = str(timedelta(seconds=round(species_shift_end - species_shift_start)))\n",
    "        species_level_time = str(timedelta(seconds=round(species_shift_end - small_carnivores_start)))\n",
    "        log.update({\"Species Level Shift Imgs Time\" : species_shift_time})\n",
    "        log.update({\"Species Level Predict and Shift\" : species_level_time})\n",
    "        \n",
    "        ## SAVE FINAL PREDICTIONS.CSV\n",
    "        \n",
    "        df_final = pd.merge(df_order, df_species, on='Cropped_image_name', how='left')\n",
    "        df_final.drop(columns=['Order_dir', 'Order_level_path','Cropped_image_path'], inplace=True)\n",
    "        df_final_path = os.path.join(data_dir, \"predictions.csv\")\n",
    "        df_final.to_csv(df_final_path, index=False)\n",
    "        \n",
    "        ## SAVE LOG FILE\n",
    "        print(\"Saving Logs\")\n",
    "        log_file_name = \"_\".join(data_dir.split(\"\\\\\")[-3:])\n",
    "        log_file_path = os.path.join(data_dir, f\"{log_file_name}_log.json\")\n",
    "        with open(log_file_path, \"w\") as f:\n",
    "            json.dump(log, f, indent=2)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7a4a592-8d69-4698-8c76-c63d0074a8f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded : True\n",
      "GPU available\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\2\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\10\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\9\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\16\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\13\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\4\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\25\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\21\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\14\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\28\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\27\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\29\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\3\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\20\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\22\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\24\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\30\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\15\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\17\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\31\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\8\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\32\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\19\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\18\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\26\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\12\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\6\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\5\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\11\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\7\n",
      "Loading Models...\n",
      "0:00:00\n",
      "\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\2\n",
      "0\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:28<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 93/93 [11:14<00:00,  7.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "748/748 [==============================] - 114s 153ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 47843/47843 [09:17<00:00, 85.77it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 47843/47843 [00:30<00:00, 1574.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 47843 images copied and removed at 2023-11-22 14:28:49.971751\n",
      "Predicting Ungulates...\n",
      "509/509 [==============================] - 78s 153ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 47843/47843 [11:53<00:00, 67.05it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 47843/47843 [00:30<00:00, 1559.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 47843 images copied and removed at 2023-11-22 14:42:37.077623\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\10\n",
      "0\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [02:23<00:00,  7.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 103/103 [19:30<00:00, 11.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "831/831 [==============================] - 127s 153ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 53177/53177 [15:47<00:00, 56.09it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 53177/53177 [00:36<00:00, 1471.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 53177 images copied and removed at 2023-11-22 15:23:31.361290\n",
      "Predicting Ungulates...\n",
      "738/738 [==============================] - 114s 154ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 53177/53177 [35:45<00:00, 24.78it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 53177/53177 [00:35<00:00, 1486.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 53177 images copied and removed at 2023-11-22 16:01:59.071779\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\9\n",
      "0\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [03:21<00:00, 10.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [11:32<00:00, 14.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "394/394 [==============================] - 61s 154ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 25163/25163 [08:58<00:00, 46.75it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 25163/25163 [00:15<00:00, 1673.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 25163 images copied and removed at 2023-11-22 16:27:24.440680\n",
      "Predicting Ungulates...\n",
      "326/326 [==============================] - 50s 154ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 25163/25163 [08:29<00:00, 49.41it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 25163/25163 [00:15<00:00, 1613.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 25163 images copied and removed at 2023-11-22 16:37:10.453279\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\16\n",
      "0\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [04:00<00:00, 12.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [02:53<00:00, 15.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "92/92 [==============================] - 15s 162ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 5846/5846 [02:17<00:00, 42.41it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 5846/5846 [00:03<00:00, 1809.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 5846 images copied and removed at 2023-11-22 16:46:58.126274\n",
      "Predicting Ungulates...\n",
      "30/30 [==============================] - 5s 159ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████████████████████████████████████████████████████████| 5846/5846 [01:50<00:00, 52.84it/s]\n",
      "Removing source images: 100%|████████████████████████████████████████████████████| 5846/5846 [00:02<00:00, 2090.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 5846 images copied and removed at 2023-11-22 16:48:58.363072\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\13\n",
      "0\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [04:12<00:00, 12.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [09:53<00:00, 16.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "296/296 [==============================] - 46s 154ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 18893/18893 [08:21<00:00, 37.65it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 18893/18893 [00:10<00:00, 1834.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 18893 images copied and removed at 2023-11-22 17:12:50.698315\n",
      "Predicting Ungulates...\n",
      "70/70 [==============================] - 11s 164ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 18893/18893 [07:10<00:00, 43.93it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 18893/18893 [00:10<00:00, 1827.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 18893 images copied and removed at 2023-11-22 17:20:24.976074\n",
      "Saving Logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\4\n",
      "0\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\\4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [04:37<00:00, 13.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Megadetector model\n",
      "Megadetector output file already exists.. Going for species classification\n",
      "Generating detections.csv...\n",
      "Cropping Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [19:15<00:00, 18.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Order Level Classes...\n",
      "513/513 [==============================] - 79s 154ms/step\n",
      "Moving Order Level Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 32814/32814 [15:53<00:00, 34.40it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 32814/32814 [00:20<00:00, 1619.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 32814 images copied and removed at 2023-11-22 18:02:09.270593\n",
      "Predicting Ungulates...\n",
      "245/245 [==============================] - 38s 154ms/step\n",
      "Moving Ungulates and Small Carnivores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████| 32814/32814 [13:48<00:00, 39.59it/s]\n",
      "Removing source images: 100%|██████████████████████████████████████████████████| 32814/32814 [00:20<00:00, 1595.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 32814 images copied and removed at 2023-11-22 18:16:59.829317\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m     handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m )\n\u001b[1;32m--> 259\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    312\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[1;32m--> 313\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\pandas\\_libs\\writers.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 259\u001b[0m\n\u001b[0;32m    257\u001b[0m df_final\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder_dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder_level_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCropped_image_path\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    258\u001b[0m df_final_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 259\u001b[0m \u001b[43mdf_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_final_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m## SAVE LOG FILE\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving Logs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\pandas\\io\\common.py:138\u001b[0m, in \u001b[0;36mIOHandles.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\pandas\\io\\common.py:130\u001b[0m, in \u001b[0;36mIOHandles.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreated_handles\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreated_handles:\n\u001b[1;32m--> 130\u001b[0m     \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreated_handles \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "##### For External drives\n",
    "\n",
    "from functions import *\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "def list_files_in_directory(directory):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg','.json','.csv')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_paths.append(file_path)\n",
    "            else:\n",
    "                continue\n",
    "    return file_paths\n",
    "    \n",
    "try:\n",
    "    print(f\"Models loaded : {areModelsLoaded}\")\n",
    "except:\n",
    "    areModelsLoaded = False\n",
    "log = {}\n",
    "now = datetime.now()\n",
    "\n",
    "data = r\"J:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\SudasariACD\\C2\"\n",
    "temp_dir = r\"E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\"\n",
    "inp = \"YES\"\n",
    "\n",
    "## CHECK FOR GPU\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpu = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "\n",
    "if gpus:\n",
    "    print(\"GPU available\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n",
    "    \n",
    "## GET SUBDIRECTORIES\n",
    "\n",
    "sub_dirs = []\n",
    "for dirpath, dirnames, filenames in os.walk(data):\n",
    "    # if \"Cropped_images\" in dirpath:\n",
    "    #     continue\n",
    "    # if dirpath == data_dir and not filenames == []:\n",
    "    #     sub_dirs.append(dirpath)\n",
    "    if not \"Cropped_images\" in dirnames and not \"Cropped_images\" in dirpath and not data == dirpath:\n",
    "        sub_dirs.append(dirpath)\n",
    "        \n",
    "if sub_dirs == []:\n",
    "    sub_dirs.append(data)\n",
    "\n",
    "for i in sub_dirs:\n",
    "    print(i)\n",
    "#inp = input(\"Check Sub directories\")\n",
    "\n",
    "\n",
    "if inp == \"YES\":\n",
    "    ## LOAD MODELS\n",
    "    print(\"Loading Models...\")\n",
    "    order_level_class_names = [\"GIB\", \"Goat_Sheep\", \"Hare\", \"Human\", \"Raptor\", \"Small Bird\", \"Small Carnivore\", \"Ungulate\", \"Vehicle\", \"Wild Pig\"]\n",
    "    order_level_class_names.sort()\n",
    "    ungulate_class_names = [\"Camel\", \"Chinkara\", \"Nilgai\", \"Cattle\"]\n",
    "    ungulate_class_names.sort() \n",
    "    small_carnivores_class_names = [\"Dog\", \"Desert Cat\", \"Fox\"]\n",
    "    small_carnivores_class_names.sort()\n",
    "    \n",
    "    model_load_start=time.time()\n",
    "    if areModelsLoaded == False:\n",
    "        order_level_model_path = os.path.join(os.getcwd(), r\"Models\\Refined_Hierarchical.ckpt\")\n",
    "        order_level_model = tf.keras.models.load_model(order_level_model_path)\n",
    "        \n",
    "        ungulate_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Ungulates_3.ckpt\")\n",
    "        ungulate_model = tf.keras.models.load_model(ungulate_model_path)   \n",
    "        \n",
    "        small_carnivore_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Small_Carnivores_1.ckpt\")\n",
    "        small_carnivore_model= tf.keras.models.load_model(small_carnivore_model_path)\n",
    "        \n",
    "        areModelsLoaded = True\n",
    "        \n",
    "    model_load_end = time.time()\n",
    "    model_load_time = str(timedelta(seconds=round(model_load_end - model_load_start)))\n",
    "    log.update({\"Species Model Load Time\" : model_load_time})\n",
    "    print(model_load_time)\n",
    "    \n",
    "    for data_dir in sub_dirs:\n",
    "        print()\n",
    "        print(data_dir)\n",
    "        ## CREATE LOGS\n",
    "        \n",
    "        log.update({\"Run timestamp\" : str(now)})\n",
    "        # log.update({\"GPU\" : gpus})\n",
    "        log.update({\"GPU Available for Classification : \" : gpu_name})\n",
    "        # log.update({\"CPU\" : cpu})\n",
    "        num_images = 0\n",
    "        for root,dirs,files in os.walk(data_dir):\n",
    "            if not root == \"Cropped_images\":\n",
    "                num_images += len(files)\n",
    "                for f in files:\n",
    "                    if not f.endswith(\".jpg\"):\n",
    "                        num_images -= 1\n",
    "        log.update({\"Num images\" : num_images})\n",
    "        print(num_images)\n",
    "\n",
    "        temp_path = os.path.join(temp_dir,\"\\\\\".join(data_dir.split(\"\\\\\")[-3:]))\n",
    "        print(temp_path)\n",
    "        os.makedirs(temp_path, exist_ok = True)\n",
    "        for dirpath, dirnames, filenames in os.walk(temp_path):\n",
    "            if not \"Cropped_images\" in dirnames and not \"Cropped_images\" in dirpath:\n",
    "                temp_copy_df=pd.DataFrame({\"src_list\" : list_files_in_directory(data_dir)})\n",
    "                temp_copy_df[\"dest_list\"] = temp_path + \"\\\\\" + temp_copy_df[\"src_list\"].apply(lambda x: x.split(\"\\\\\")[-1])\n",
    "                copy_images_batch(temp_copy_df['src_list'],temp_copy_df['dest_list'], batch_size=512)\n",
    "        #folder_name = \"_\".join(data_dir.split(\"\\\\\")[-3:])\n",
    "        #megadetector_name = f\"{folder_name}_megadetector.json\"\n",
    "        #try:\n",
    "            #shutil.move(os.path.join(data_dir, megadetector_name),os.path.join(temp_path, megadetector_name))\n",
    "        #except:\n",
    "            #print(\"Megadetector file not available\")\n",
    "        \n",
    "        ## RUN MEGADETECTOR AND CREATE DETECTIONS.DF\n",
    "        \n",
    "        megadetector_start = time.time()\n",
    "        json_dir, megadetector_log = megadetector(temp_path, num_images)\n",
    "        if not megadetector_log == {}:\n",
    "            log.update(megadetector_log)\n",
    "        else:\n",
    "            megadetector_end = time.time()\n",
    "            megadetector_time = str(timedelta(seconds=round(megadetector_end - megadetector_start)))\n",
    "            log.update({\"Megadetector time\" : megadetector_time})\n",
    "            log.update({\"Megadetector Filename\" : os.path.basename(json_dir)})\n",
    "\n",
    "        df_detections = get_detection_df(temp_path, json_dir)\n",
    "        gc.collect()\n",
    "        ## CROP IMAGES\n",
    "        \n",
    "        cropping_start = time.time() \n",
    "        cropped_images = os.path.join(temp_path,r\"Cropped_images\\*\")\n",
    "        cropped_dir = clean_path(\"\\\\\".join(cropped_images.split(\"\\\\\")[:-1]))\n",
    "        if not os.path.exists(cropped_dir):\n",
    "            print(\"Cropping Images\")\n",
    "            df_crop = df_detections.copy()\n",
    "            df_crop[\"Cropped_image_directory\"] = cropped_dir\n",
    "            df_crop[\"Cropped_image_name\"] = df_crop[\"Filename\"] + \"_\" + df_crop[\"Detection_number\"].astype(str) + \".jpg\"\n",
    "            df_crop[\"Cropped_image_path\"] = (cropped_dir + \"\\\\\" + df_crop[\"Cropped_image_name\"]).apply(clean_path)\n",
    "            df_crop=crop_images_batch_gpu(df_crop,512)\n",
    "        else:\n",
    "            print(\"Images already cropped...\")\n",
    "        cropping_end = time.time()\n",
    "        cropping_time = str(timedelta(seconds=round(cropping_end - cropping_start)))\n",
    "        log.update({\"Cropping Time\" : cropping_time})\n",
    "        log.update({\"Number of Detections\" : len(df_detections)})\n",
    "        \n",
    "        ## ORDER LEVEL PREDICTIONS\n",
    "\n",
    "        gc.collect()\n",
    "        order_level_start = time.time()\n",
    "        print(\"Predicting Order Level Classes...\")\n",
    "        df_temp, num_cropped = predict_lower_level_species(temp_path, \n",
    "                                                           r\"Cropped_images\\*\", \n",
    "                                                           order_level_class_names,\n",
    "                                                           order_level_model,\n",
    "                                                           level = \"Order\")\n",
    "        \n",
    "        order_level_end = time.time()\n",
    "        df_order = pd.merge(df_crop, df_temp, on='Cropped_image_name', how='left')\n",
    "        df_order[\"Order_pred\"] = df_order[\"Order_pred\"].fillna(\"Error\")\n",
    "        df_order[\"Order_dir\"] = (cropped_dir + \"\\\\\" + df_order[\"Order_pred\"]).apply(clean_path)\n",
    "        df_order[\"Order_level_path\"] = (df_order[\"Order_dir\"] + \"\\\\\" + df_order[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        unique_directories = set(df_order['Order_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Order Level Images...\")\n",
    "        #copy_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        #delete_images_batch(df_order[\"Cropped_image_path\"])\n",
    "        move_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        \n",
    "        order_shift_end = time.time()\n",
    "        order_pred_time = str(timedelta(seconds=round(order_level_end - order_level_start)))\n",
    "        order_shift_time = str(timedelta(seconds=round(order_shift_end - order_level_end)))\n",
    "        log.update({\"Order Level Prediction Time\" : order_shift_time})\n",
    "        log.update({\"Order Level Shifting Time\" : order_shift_time})\n",
    "        gc.collect()\n",
    "        \n",
    "        ## SMALL CARNIVORES PREDICT\n",
    "        small_carnivores_start = time.time()\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Small_Carnivore\")):\n",
    "            print(\"Predicting Small Carnivores...\")\n",
    "            df_small_carnivore, num_small_carnivores = predict_lower_level_species(cropped_dir, \n",
    "                                                                                   r\"Small Carnivore\\*\", \n",
    "                                                                                   small_carnivores_class_names,\n",
    "                                                                                   small_carnivore_model,\n",
    "                                                                                   level = \"Species\")\n",
    "            \n",
    "            small_carnivores_end = time.time()\n",
    "            small_carnivore_time = str(timedelta(seconds=round(small_carnivores_end - small_carnivores_start)))\n",
    "            log.update({\"Number of Small Carnivores Images\" : num_small_carnivores})\n",
    "            log.update({\"Small Carnivore Model Pred Time\" : small_carnivore_time})\n",
    "        else:\n",
    "            df_small_carnivore = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "       \n",
    "        ## UNGULATES PREDICT\n",
    "\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Ungulate\")):\n",
    "            ungulate_start = time.time()\n",
    "            print(\"Predicting Ungulates...\")\n",
    "            df_ungulate, num_ungulates = predict_lower_level_species(cropped_dir, \n",
    "                                                                     r\"Ungulate\\*\", \n",
    "                                                                     ungulate_class_names,\n",
    "                                                                     ungulate_model,\n",
    "                                                                     level = \"Species\")\n",
    "            \n",
    "            ungulate_end = time.time()\n",
    "            ungulate_time = str(timedelta(seconds=round(ungulate_end - ungulate_start)))\n",
    "            log.update({\"Number of Ungulates Images\" : num_ungulates})\n",
    "            log.update({\"Ungulate Model Pred Time\" : ungulate_time})\n",
    "        else:\n",
    "            df_ungulate = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "        \n",
    "        species_shift_start = time.time()\n",
    "        df_species = pd.concat([df_small_carnivore,df_ungulate])\n",
    "        cropped_dir_final = os.path.join(data_dir, r\"Cropped_images\")\n",
    "        df_species[\"Species_dir\"] = (cropped_dir_final + \"\\\\\" + df_species[\"Species_pred\"]).apply(clean_path)\n",
    "        df_species[\"Species_level_path\"] = (df_species[\"Species_dir\"] + \"\\\\\" + df_species[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        df_move = pd.merge(df_order[[\"Cropped_image_name\",\"Order_level_path\",\"Order_pred\"]],df_species, on='Cropped_image_name', how='left')\n",
    "        df_move[\"Species_pred\"]= df_move[\"Species_pred\"].fillna(df_move[\"Order_pred\"])\n",
    "        df_move[\"Species_dir\"] = (cropped_dir_final + \"\\\\\" + df_move[\"Species_pred\"]).apply(clean_path)\n",
    "        df_move[\"Species_level_path\"] = (df_move[\"Species_dir\"] + \"\\\\\" + df_move[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        df_move = df_move[df_move[\"Order_level_path\"] != df_move[\"Species_level_path\"]]\n",
    "        unique_directories = set(df_move['Species_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Ungulates and Small Carnivores...\")\n",
    "        #copy_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        #delete_images_batch(df_move[\"Order_level_path\"])\n",
    "        move_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        \n",
    "        species_shift_end = time.time()\n",
    "        species_shift_time = str(timedelta(seconds=round(species_shift_end - species_shift_start)))\n",
    "        species_level_time = str(timedelta(seconds=round(species_shift_end - small_carnivores_start)))\n",
    "        log.update({\"Species Level Shift Imgs Time\" : species_shift_time})\n",
    "        log.update({\"Species Level Predict and Shift\" : species_level_time})\n",
    "        \n",
    "        ## SAVE FINAL PREDICTIONS.CSV\n",
    "        \n",
    "        df_final = pd.merge(df_order, df_species, on='Cropped_image_name', how='left')\n",
    "        df_final.drop(columns=['Order_dir', 'Order_level_path','Cropped_image_path'], inplace=True)\n",
    "        df_final_path = os.path.join(data_dir, \"predictions.csv\")\n",
    "        df_final.to_csv(df_final_path, index=False)\n",
    "        \n",
    "        ## SAVE LOG FILE\n",
    "        print(\"Saving Logs\")\n",
    "        log_file_name = \"_\".join(data_dir.split(\"\\\\\")[-3:])\n",
    "        log_file_path = os.path.join(data_dir, f\"{log_file_name}_log.json\")\n",
    "        log.update({\"Storage\" : \"External\"})\n",
    "        with open(log_file_path, \"w\") as f:\n",
    "            json.dump(log, f, indent=2)\n",
    "        delete_images_batch(temp_copy_df['dest_list'])\n",
    "        shutil.rmtree(temp_path)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce05f96b-4a44-4e7e-aefe-79df6ee0dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39470da2-9072-465e-8574-211adc56b73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n",
      "E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\Ganga\\Ganga2\n",
      "Loading Models...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m areModelsLoaded \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     order_level_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRefined_Hierarchical.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m     order_level_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder_level_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     ungulate_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEfficient_Net_Ungulates_3.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m     ungulate_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(ungulate_model_path)   \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\keras\\saving\\save.py:209\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaved_model_load\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\keras\\saving\\saved_model\\load.py:141\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_id, loaded_node \u001b[38;5;129;01min\u001b[39;00m keras_loader\u001b[38;5;241m.\u001b[39mloaded_nodes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    140\u001b[0m   nodes_to_load[keras_loader\u001b[38;5;241m.\u001b[39mget_path(node_id)] \u001b[38;5;241m=\u001b[39m loaded_node\n\u001b[1;32m--> 141\u001b[0m loaded \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Finalize the loaded layers and remove the extra tracked dependencies.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m keras_loader\u001b[38;5;241m.\u001b[39mfinalize_objects()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:912\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 912\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_graph_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_model_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mckpt_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m         \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    919\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:151\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proto \u001b[38;5;241m=\u001b[39m object_graph_proto\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_dir \u001b[38;5;241m=\u001b[39m export_dir\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 151\u001b[0m     \u001b[43mfunction_deserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_function_def_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43msaved_object_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapper_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_WrapperFunction\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# captures.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restored_concrete_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:430\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_input_shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fdef\u001b[38;5;241m.\u001b[39mattr:\n\u001b[0;32m    429\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m fdef\u001b[38;5;241m.\u001b[39mattr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_input_shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 430\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcreteFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfdef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrapper_function:\n\u001b[0;32m    432\u001b[0m   func \u001b[38;5;241m=\u001b[39m wrapper_function(func)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1492\u001b[0m, in \u001b[0;36mConcreteFunction.__init__\u001b[1;34m(self, func_graph, attrs, shared_func_graph, spec)\u001b[0m\n\u001b[0;32m   1486\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_garbage_collector \u001b[38;5;241m=\u001b[39m ConcreteFunctionGarbageCollector(func_graph)\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;66;03m# Pairs of forward and backward functions used for computing gradients.\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;66;03m# These each get a reference to the FuncGraph deleter since they use the\u001b[39;00m\n\u001b[0;32m   1491\u001b[0m \u001b[38;5;66;03m# FuncGraph directly.\u001b[39;00m\n\u001b[1;32m-> 1492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delayed_rewrite_functions \u001b[38;5;241m=\u001b[39m \u001b[43m_DelayedRewriteGradientFunctions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_garbage_collector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_order_tape_functions \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_higher_order_tape_functions \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:582\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.__init__\u001b[1;34m(self, func_graph, attrs, func_graph_deleter)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_function_pairs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph \u001b[38;5;241m=\u001b[39m func_graph\n\u001b[1;32m--> 582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function \u001b[38;5;241m=\u001b[39m \u001b[43m_EagerDefinedFunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_inference_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;241m=\u001b[39m attrs\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cameratraps-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:358\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.__init__\u001b[1;34m(self, name, graph, inputs, outputs, attrs)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m   output_names \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 358\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_GraphToFunction_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moperations\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_tf_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_tf_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol_outputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# control_output_names\u001b[39;49;00m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_func \u001b[38;5;241m=\u001b[39m c_api_util\u001b[38;5;241m.\u001b[39mScopedTFFunction(fn, name)\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, attr_value \u001b[38;5;129;01min\u001b[39;00m attrs\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "import torch\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "areModelsLoaded = False\n",
    "log = {}\n",
    "now = datetime.now()\n",
    "\n",
    "data = r\"E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\Ganga\\Ganga2\"\n",
    "inp = \"YES\"\n",
    "\n",
    "## CHECK FOR GPU\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpu = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "\n",
    "if gpus:\n",
    "    print(\"GPU available\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n",
    "    \n",
    "## GET SUBDIRECTORIES\n",
    "\n",
    "sub_dirs = []\n",
    "for dirpath, dirnames, filenames in os.walk(data):\n",
    "    # if \"Cropped_images\" in dirpath:\n",
    "    #     continue\n",
    "    # if dirpath == data_dir and not filenames == []:\n",
    "    #     sub_dirs.append(dirpath)\n",
    "    if not \"Cropped_images\" in dirnames and not \"Cropped_images\" in dirpath and not data == dirpath:\n",
    "        sub_dirs.append(dirpath)\n",
    "        \n",
    "if sub_dirs == []:\n",
    "    sub_dirs.append(data)\n",
    "\n",
    "for i in sub_dirs:\n",
    "    print(i)\n",
    "#inp = input(\"Check Sub directories\")\n",
    "\n",
    "\n",
    "if inp == \"YES\":\n",
    "    ## LOAD MODELS\n",
    "    print(\"Loading Models...\")\n",
    "    order_level_class_names = [\"GIB\", \"Goat_Sheep\", \"Hare\", \"Human\", \"Raptor\", \"Small Bird\", \"Small Carnivore\", \"Ungulate\", \"Vehicle\", \"Wild Pig\"]\n",
    "    order_level_class_names.sort()\n",
    "    ungulate_class_names = [\"Camel\", \"Chinkara\", \"Nilgai\", \"Cattle\"]\n",
    "    ungulate_class_names.sort() \n",
    "    small_carnivores_class_names = [\"Dog\", \"Desert Cat\", \"Fox\"]\n",
    "    small_carnivores_class_names.sort()\n",
    "    \n",
    "    model_load_start=time.time()\n",
    "    if areModelsLoaded == False:\n",
    "        order_level_model_path = os.path.join(os.getcwd(), r\"Models\\Refined_Hierarchical.ckpt\")\n",
    "        order_level_model = tf.keras.models.load_model(order_level_model_path)\n",
    "        \n",
    "        ungulate_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Ungulates_3.ckpt\")\n",
    "        ungulate_model = tf.keras.models.load_model(ungulate_model_path)   \n",
    "        \n",
    "        small_carnivore_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Small_Carnivores_1.ckpt\")\n",
    "        small_carnivore_model= tf.keras.models.load_model(small_carnivore_model_path)\n",
    "        \n",
    "        areModelsLoaded = True\n",
    "        \n",
    "    model_load_end = time.time()\n",
    "    model_load_time = str(timedelta(seconds=round(model_load_end - model_load_start)))\n",
    "    log.update({\"Species Model Load Time\" : model_load_time})\n",
    "    print(model_load_time)\n",
    "    \n",
    "    for data_dir in sub_dirs:\n",
    "        print()\n",
    "        print(data_dir)\n",
    "        ## CREATE LOGS\n",
    "        \n",
    "        log.update({\"Run timestamp\" : str(now)})\n",
    "        # log.update({\"GPU\" : gpus})\n",
    "        log.update({\"GPU Available for Classification : \" : gpu_name})\n",
    "        # log.update({\"CPU\" : cpu})\n",
    "        num_images = 0\n",
    "        for root,dirs,files in os.walk(data_dir):\n",
    "            if not root == \"Cropped_images\":\n",
    "                num_images += len(files)\n",
    "                for f in files:\n",
    "                    if not f.endswith(\".jpg\"):\n",
    "                        num_images -= 1\n",
    "        log.update({\"Num images\" : num_images})\n",
    "        print(num_images)\n",
    "        \n",
    "        ## RUN MEGADETECTOR AND CREATE DETECTIONS.DF\n",
    "        \n",
    "        megadetector_start = time.time()\n",
    "        json_dir, megadetector_log = megadetector(data_dir, num_images)\n",
    "        if not megadetector_log == {}:\n",
    "            log.update(megadetector_log)\n",
    "        else:\n",
    "            megadetector_end = time.time()\n",
    "            megadetector_time = str(timedelta(seconds=round(megadetector_end - megadetector_start)))\n",
    "            log.update({\"Megadetector time\" : megadetector_time})\n",
    "            log.update({\"Megadetector Filename\" : os.path.basename(json_dir)})\n",
    "\n",
    "        detections_dir = os.path.join(data_dir, \"detections.csv\")\n",
    "        if not os.path.exists(detections_dir):\n",
    "            df_detections = get_detection_df(data_dir, json_dir)\n",
    "        else:\n",
    "            print(\"Detections.csv exists...\")\n",
    "            df_detections = pd.read_csv(detections_dir)\n",
    "        \n",
    "        \n",
    "        ## CROP IMAGES\n",
    "        \n",
    "        cropping_start = time.time() \n",
    "        cropped_images = os.path.join(data_dir,r\"Cropped_images\\*\")\n",
    "        cropped_dir = clean_path(\"\\\\\".join(cropped_images.split(\"\\\\\")[:-1]))\n",
    "        if not os.path.exists(cropped_dir):\n",
    "            print(\"Cropping Images\")\n",
    "            try:\n",
    "                df_crop=crop_images_batch2(df_detections,512)\n",
    "            except:\n",
    "                df_crop = df_detections\n",
    "                df_crop[\"Cropped_image_name\"] = df_crop[\"Filename\"] + \"_\" + df_crop[\"Detection_number\"].astype(str) + \".jpg\"\n",
    "                #df_crop=crop_images_batch2(df_detections,512)\n",
    "                print(f\"Cropping exception occured\")\n",
    "            df_crop[\"Cropped_image_path\"] = (cropped_dir + \"\\\\\" + df_crop[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        else:\n",
    "            print(\"Images already cropped...\")\n",
    "        cropping_end = time.time()\n",
    "        cropping_time = str(timedelta(seconds=round(cropping_end - cropping_start)))\n",
    "        log.update({\"Cropping Time\" : cropping_time})\n",
    "        log.update({\"Number of Detections\" : len(df_detections)})\n",
    "        \n",
    "        ## ORDER LEVEL PREDICTIONS\n",
    "        \n",
    "        order_level_start = time.time()\n",
    "        print(\"Predicting Order Level Classes...\")\n",
    "        df_temp, num_cropped = predict_lower_level_species(data_dir, \n",
    "                                                           r\"Cropped_images\\*\", \n",
    "                                                           order_level_class_names,\n",
    "                                                           order_level_model,\n",
    "                                                           level = \"Order\")\n",
    "        \n",
    "        order_level_end = time.time()\n",
    "        df_order = pd.merge(df_crop, df_temp, on='Cropped_image_name', how='left')\n",
    "        df_order[\"Order_pred\"] = df_order[\"Order_pred\"].fillna(\"Error\")\n",
    "        df_order[\"Order_dir\"] = (cropped_dir + \"\\\\\" + df_order[\"Order_pred\"]).apply(clean_path)\n",
    "        df_order[\"Order_level_path\"] = (df_order[\"Order_dir\"] + \"\\\\\" + df_order[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        unique_directories = set(df_order['Order_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Order Level Images...\")\n",
    "        #copy_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        #delete_images_batch(df_order[\"Cropped_image_path\"])\n",
    "        move_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        \n",
    "        order_shift_end = time.time()\n",
    "        order_pred_time = str(timedelta(seconds=round(order_level_end - order_level_start)))\n",
    "        order_shift_time = str(timedelta(seconds=round(order_shift_end - order_level_end)))\n",
    "        log.update({\"Order Level Prediction Time\" : order_shift_time})\n",
    "        log.update({\"Order Level Shifting Time\" : order_shift_time})\n",
    "        \n",
    "        \n",
    "        ## SMALL CARNIVORES PREDICT\n",
    "        small_carnivores_start = time.time()\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Small_Carnivore\")):\n",
    "            print(\"Predicting Small Carnivores...\")\n",
    "            df_small_carnivore, num_small_carnivores = predict_lower_level_species(cropped_dir, \n",
    "                                                                                   r\"Small Carnivore\\*\", \n",
    "                                                                                   small_carnivores_class_names,\n",
    "                                                                                   small_carnivore_model,\n",
    "                                                                                   level = \"Species\")\n",
    "            \n",
    "            small_carnivores_end = time.time()\n",
    "            small_carnivore_time = str(timedelta(seconds=round(small_carnivores_end - small_carnivores_start)))\n",
    "            log.update({\"Number of Small Carnivores Images\" : num_small_carnivores})\n",
    "            log.update({\"Small Carnivore Model Pred Time\" : small_carnivore_time})\n",
    "        else:\n",
    "            df_small_carnivore = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "       \n",
    "        ## UNGULATES PREDICT\n",
    "\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Ungulate\")):\n",
    "            ungulate_start = time.time()\n",
    "            print(\"Predicting Ungulates...\")\n",
    "            df_ungulate, num_ungulates = predict_lower_level_species(cropped_dir, \n",
    "                                                                     r\"Ungulate\\*\", \n",
    "                                                                     ungulate_class_names,\n",
    "                                                                     ungulate_model,\n",
    "                                                                     level = \"Species\")\n",
    "            \n",
    "            ungulate_end = time.time()\n",
    "            ungulate_time = str(timedelta(seconds=round(ungulate_end - ungulate_start)))\n",
    "            log.update({\"Number of Ungulates Images\" : num_ungulates})\n",
    "            log.update({\"Ungulate Model Pred Time\" : ungulate_time})\n",
    "        else:\n",
    "            df_ungulate = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "        \n",
    "        species_shift_start = time.time()\n",
    "        df_species = pd.concat([df_small_carnivore,df_ungulate])\n",
    "        df_species[\"Species_dir\"] = (cropped_dir + \"\\\\\" + df_species[\"Species_pred\"]).apply(clean_path)\n",
    "        df_species[\"Species_level_path\"] = (df_species[\"Species_dir\"] + \"\\\\\" + df_species[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        df_move = pd.merge(df_species, df_order, on='Cropped_image_name', how='left')\n",
    "        df_move = df_move[df_move[\"Order_level_path\"] != df_move[\"Species_level_path\"]]\n",
    "        unique_directories = set(df_move['Species_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Ungulates and Small Carnivores...\")\n",
    "        #copy_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        #delete_images_batch(df_move[\"Order_level_path\"])\n",
    "        move_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        \n",
    "        species_shift_end = time.time()\n",
    "        species_shift_time = str(timedelta(seconds=round(species_shift_end - species_shift_start)))\n",
    "        species_level_time = str(timedelta(seconds=round(species_shift_end - small_carnivores_start)))\n",
    "        log.update({\"Species Level Shift Imgs Time\" : species_shift_time})\n",
    "        log.update({\"Species Level Predict and Shift\" : species_level_time})\n",
    "        \n",
    "        ## SAVE FINAL PREDICTIONS.CSV\n",
    "        \n",
    "        df_final = pd.merge(df_order, df_species, on='Cropped_image_name', how='left')\n",
    "        df_final.drop(columns=['Order_dir', 'Order_level_path','Cropped_image_path'], inplace=True)\n",
    "        df_final_path = os.path.join(data_dir, \"predictions.csv\")\n",
    "        df_final.to_csv(df_final_path, index=False)\n",
    "        \n",
    "        ## SAVE LOG FILE\n",
    "        print(\"Saving Logs\")\n",
    "        log_file_name = \"_\".join(data_dir.split(\"\\\\\")[-3:])\n",
    "        log_file_path = os.path.join(data_dir, f\"{log_file_name}_log.json\")\n",
    "        with open(log_file_path, \"w\") as f:\n",
    "            json.dump(log, f, indent=2)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb199318-feda-4690-bc53-83202cc588c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.normpath(df_detections.File_directory.iloc[1]) not in os.path.normpath(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55cde9b-237d-43ab-bdbf-e0105f80a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "garbage=gc.collect()\n",
    "gc.get_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a8445b-fd08-4e67-a5db-3cda505cfba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "areModelsLoaded = False\n",
    "log = {}\n",
    "now = datetime.now()\n",
    "\n",
    "data = r\"E:\\Camera_Trapping\\Guzzler_data\\2023\\CameraTrap\\RKVY\\RKVY\"\n",
    "inp = \"YES\"\n",
    "\n",
    "## CHECK FOR GPU\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpu = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "\n",
    "if gpus:\n",
    "    print(\"GPU available\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n",
    "    \n",
    "## GET SUBDIRECTORIES\n",
    "\n",
    "sub_dirs = []\n",
    "for dirpath, dirnames, filenames in os.walk(data):\n",
    "    # if \"Cropped_images\" in dirpath:\n",
    "    #     continue\n",
    "    # if dirpath == data_dir and not filenames == []:\n",
    "    #     sub_dirs.append(dirpath)\n",
    "    if not \"Cropped_images\" in dirnames and not \"Cropped_images\" in dirpath and not data == dirpath:\n",
    "        sub_dirs.append(dirpath)\n",
    "        \n",
    "if sub_dirs == []:\n",
    "    sub_dirs.append(data)\n",
    "\n",
    "for i in sub_dirs:\n",
    "    print(i)\n",
    "#inp = input(\"Check Sub directories\")\n",
    "\n",
    "\n",
    "if inp == \"YES\":\n",
    "    ## LOAD MODELS\n",
    "    print(\"Loading Models...\")\n",
    "    order_level_class_names = [\"GIB\", \"Goat_Sheep\", \"Hare\", \"Human\", \"Raptor\", \"Small Bird\", \"Small Carnivore\", \"Ungulate\", \"Vehicle\", \"Wild Pig\"]\n",
    "    order_level_class_names.sort()\n",
    "    ungulate_class_names = [\"Camel\", \"Chinkara\", \"Nilgai\", \"Cattle\"]\n",
    "    ungulate_class_names.sort() \n",
    "    small_carnivores_class_names = [\"Dog\", \"Desert Cat\", \"Fox\"]\n",
    "    small_carnivores_class_names.sort()\n",
    "    \n",
    "    model_load_start=time.time()\n",
    "    if areModelsLoaded == False:\n",
    "        order_level_model_path = os.path.join(os.getcwd(), r\"Models\\Refined_Hierarchical.ckpt\")\n",
    "        order_level_model = tf.keras.models.load_model(order_level_model_path)\n",
    "        \n",
    "        ungulate_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Ungulates_3.ckpt\")\n",
    "        ungulate_model = tf.keras.models.load_model(ungulate_model_path)   \n",
    "        \n",
    "        small_carnivore_model_path = os.path.join(os.getcwd(), r\"Models\\Efficient_Net_Small_Carnivores_1.ckpt\")\n",
    "        small_carnivore_model= tf.keras.models.load_model(small_carnivore_model_path)\n",
    "        \n",
    "        areModelsLoaded = True\n",
    "        \n",
    "    model_load_end = time.time()\n",
    "    model_load_time = str(timedelta(seconds=round(model_load_end - model_load_start)))\n",
    "    log.update({\"Species Model Load Time\" : model_load_time})\n",
    "    print(model_load_time)\n",
    "    \n",
    "    for data_dir in sub_dirs:\n",
    "        print()\n",
    "        print(data_dir)\n",
    "        ## CREATE LOGS\n",
    "        \n",
    "        log.update({\"Run timestamp\" : str(now)})\n",
    "        # log.update({\"GPU\" : gpus})\n",
    "        log.update({\"GPU Available for Classification : \" : gpu_name})\n",
    "        # log.update({\"CPU\" : cpu})\n",
    "        num_images = 0\n",
    "        for root,dirs,files in os.walk(data_dir):\n",
    "            if not root == \"Cropped_images\":\n",
    "                num_images += len(files)\n",
    "                for f in files:\n",
    "                    if not f.endswith(\".jpg\"):\n",
    "                        num_images -= 1\n",
    "        log.update({\"Num images\" : num_images})\n",
    "        print(num_images)\n",
    "        \n",
    "        ## RUN MEGADETECTOR AND CREATE DETECTIONS.DF\n",
    "        \n",
    "        megadetector_start = time.time()\n",
    "        json_dir, megadetector_log = megadetector(data_dir, num_images)\n",
    "        if not megadetector_log == {}:\n",
    "            log.update(megadetector_log)\n",
    "        else:\n",
    "            megadetector_end = time.time()\n",
    "            megadetector_time = str(timedelta(seconds=round(megadetector_end - megadetector_start)))\n",
    "            log.update({\"Megadetector time\" : megadetector_time})\n",
    "            log.update({\"Megadetector Filename\" : os.path.basename(json_dir)})\n",
    "\n",
    "        detections_dir = os.path.join(data_dir, \"detections.csv\")\n",
    "        if not os.path.exists(detections_dir):\n",
    "            df_detections = get_detection_df(data_dir, json_dir)\n",
    "        else:\n",
    "            print(\"Detections.csv exists...\")\n",
    "            df_detections = pd.read_csv(detections_dir)\n",
    "        \n",
    "        \n",
    "        ## CROP IMAGES\n",
    "        \n",
    "        cropping_start = time.time() \n",
    "        cropped_images = os.path.join(data_dir,r\"Cropped_images\\*\")\n",
    "        cropped_dir = clean_path(\"\\\\\".join(cropped_images.split(\"\\\\\")[:-1]))\n",
    "        if not os.path.exists(cropped_dir):\n",
    "            print(\"Cropping Images\")\n",
    "            try:\n",
    "                df_crop=crop_images_batch2(df_detections,512)\n",
    "            except:\n",
    "                df_crop = df_detections\n",
    "                df_crop[\"Cropped_image_name\"] = df_crop[\"Filename\"] + \"_\" + df_crop[\"Detection_number\"].astype(str) + \".jpg\"\n",
    "                #df_crop=crop_images_batch2(df_detections,512)\n",
    "                print(f\"Cropping exception occured\")\n",
    "            df_crop[\"Cropped_image_path\"] = (cropped_dir + \"\\\\\" + df_crop[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        else:\n",
    "            print(\"Images already cropped...\")\n",
    "        cropping_end = time.time()\n",
    "        cropping_time = str(timedelta(seconds=round(cropping_end - cropping_start)))\n",
    "        log.update({\"Cropping Time\" : cropping_time})\n",
    "        log.update({\"Number of Detections\" : len(df_detections)})\n",
    "        \n",
    "        ## ORDER LEVEL PREDICTIONS\n",
    "        \n",
    "        order_level_start = time.time()\n",
    "        print(\"Predicting Order Level Classes...\")\n",
    "        df_temp, num_cropped = predict_lower_level_species(data_dir, \n",
    "                                                           r\"Cropped_images\\*\", \n",
    "                                                           order_level_class_names,\n",
    "                                                           order_level_model,\n",
    "                                                           level = \"Order\")\n",
    "        \n",
    "        order_level_end = time.time()\n",
    "        df_order = pd.merge(df_crop, df_temp, on='Cropped_image_name', how='left')\n",
    "        df_order[\"Order_pred\"] = df_order[\"Order_pred\"].fillna(\"Error\")\n",
    "        df_order[\"Order_dir\"] = (cropped_dir + \"\\\\\" + df_order[\"Order_pred\"]).apply(clean_path)\n",
    "        df_order[\"Order_level_path\"] = (df_order[\"Order_dir\"] + \"\\\\\" + df_order[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        unique_directories = set(df_order['Order_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Order Level Images...\")\n",
    "        #copy_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        #delete_images_batch(df_order[\"Cropped_image_path\"])\n",
    "        move_images_batch(df_order[\"Cropped_image_path\"], df_order[\"Order_level_path\"])\n",
    "        \n",
    "        order_shift_end = time.time()\n",
    "        order_pred_time = str(timedelta(seconds=round(order_level_end - order_level_start)))\n",
    "        order_shift_time = str(timedelta(seconds=round(order_shift_end - order_level_end)))\n",
    "        log.update({\"Order Level Prediction Time\" : order_shift_time})\n",
    "        log.update({\"Order Level Shifting Time\" : order_shift_time})\n",
    "        \n",
    "        \n",
    "        ## SMALL CARNIVORES PREDICT\n",
    "        small_carnivores_start = time.time()\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Small_Carnivore\")):\n",
    "            print(\"Predicting Small Carnivores...\")\n",
    "            df_small_carnivore, num_small_carnivores = predict_lower_level_species(cropped_dir, \n",
    "                                                                                   r\"Small Carnivore\\*\", \n",
    "                                                                                   small_carnivores_class_names,\n",
    "                                                                                   small_carnivore_model,\n",
    "                                                                                   level = \"Species\")\n",
    "            \n",
    "            small_carnivores_end = time.time()\n",
    "            small_carnivore_time = str(timedelta(seconds=round(small_carnivores_end - small_carnivores_start)))\n",
    "            log.update({\"Number of Small Carnivores Images\" : num_small_carnivores})\n",
    "            log.update({\"Small Carnivore Model Pred Time\" : small_carnivore_time})\n",
    "        else:\n",
    "            df_small_carnivore = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "       \n",
    "        ## UNGULATES PREDICT\n",
    "\n",
    "        if os.path.exists(os.path.join(cropped_dir,r\"Ungulate\")):\n",
    "            ungulate_start = time.time()\n",
    "            print(\"Predicting Ungulates...\")\n",
    "            df_ungulate, num_ungulates = predict_lower_level_species(cropped_dir, \n",
    "                                                                     r\"Ungulate\\*\", \n",
    "                                                                     ungulate_class_names,\n",
    "                                                                     ungulate_model,\n",
    "                                                                     level = \"Species\")\n",
    "            \n",
    "            ungulate_end = time.time()\n",
    "            ungulate_time = str(timedelta(seconds=round(ungulate_end - ungulate_start)))\n",
    "            log.update({\"Number of Ungulates Images\" : num_ungulates})\n",
    "            log.update({\"Ungulate Model Pred Time\" : ungulate_time})\n",
    "        else:\n",
    "            df_ungulate = pd.DataFrame(columns=['Cropped_image_name','Species_pred','Species_pred_prob'])\n",
    "        \n",
    "        species_shift_start = time.time()\n",
    "        df_species = pd.concat([df_small_carnivore,df_ungulate])\n",
    "        df_species[\"Species_dir\"] = (cropped_dir + \"\\\\\" + df_species[\"Species_pred\"]).apply(clean_path)\n",
    "        df_species[\"Species_level_path\"] = (df_species[\"Species_dir\"] + \"\\\\\" + df_species[\"Cropped_image_name\"]).apply(clean_path)\n",
    "        \n",
    "        df_move = pd.merge(df_species, df_order, on='Cropped_image_name', how='left')\n",
    "        df_move = df_move[df_move[\"Order_level_path\"] != df_move[\"Species_level_path\"]]\n",
    "        unique_directories = set(df_move['Species_dir'])\n",
    "        for directory in unique_directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        print(\"Moving Ungulates and Small Carnivores...\")\n",
    "        #copy_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        #delete_images_batch(df_move[\"Order_level_path\"])\n",
    "        move_images_batch(df_move[\"Order_level_path\"], df_move[\"Species_level_path\"])\n",
    "        \n",
    "        species_shift_end = time.time()\n",
    "        species_shift_time = str(timedelta(seconds=round(species_shift_end - species_shift_start)))\n",
    "        species_level_time = str(timedelta(seconds=round(species_shift_end - small_carnivores_start)))\n",
    "        log.update({\"Species Level Shift Imgs Time\" : species_shift_time})\n",
    "        log.update({\"Species Level Predict and Shift\" : species_level_time})\n",
    "        \n",
    "        ## SAVE FINAL PREDICTIONS.CSV\n",
    "        \n",
    "        df_final = pd.merge(df_order, df_species, on='Cropped_image_name', how='left')\n",
    "        df_final.drop(columns=['Order_dir', 'Order_level_path','Cropped_image_path'], inplace=True)\n",
    "        df_final_path = os.path.join(data_dir, \"predictions.csv\")\n",
    "        df_final.to_csv(df_final_path, index=False)\n",
    "        \n",
    "        ## SAVE LOG FILE\n",
    "        print(\"Saving Logs\")\n",
    "        log_file_name = \"_\".join(data_dir.split(\"\\\\\")[-3:])\n",
    "        log_file_path = os.path.join(data_dir, f\"{log_file_name}_log.json\")\n",
    "        with open(log_file_path, \"w\") as f:\n",
    "            json.dump(log, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57168c5d-439d-405d-a51b-28bf31ae995f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cameratraps-env] *",
   "language": "python",
   "name": "conda-env-cameratraps-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
